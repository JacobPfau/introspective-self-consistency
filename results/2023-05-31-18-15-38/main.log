[2023-05-31 18:15:38,737][src.utils][INFO] - Git sha: 8a0147a358b27f9554efa19981c87d7906bd811e
[2023-05-31 18:15:38,752][src.utils][INFO] - Changed files: ['conf/tasks/compute_dependence_with_base_changes.yaml', 'src/evals/evaluate_continuation.py', 'src/evals/prompts/distribution_prompt.py', 'src/evals/prompts/explanation_prompt.py', 'src/evals/sequence_completion_with_base_change.py', 'src/evals/utils.py', 'src/tests/tests_q11.py']
[2023-05-31 18:15:38,765][src.utils][INFO] - Git diff:
diff --git a/conf/tasks/compute_dependence_with_base_changes.yaml b/conf/tasks/compute_dependence_with_base_changes.yaml
index 3e1ca35..366c20f 100644
--- a/conf/tasks/compute_dependence_with_base_changes.yaml
+++ b/conf/tasks/compute_dependence_with_base_changes.yaml
@@ -1,4 +1,4 @@
-sequence_type: integer
+sequence_type: binary
 model: gpt-3.5-turbo
 num_shots: 4
 on_ambiguous_sequences: true
diff --git a/src/evals/evaluate_continuation.py b/src/evals/evaluate_continuation.py
index e1f7f45..a7ed86f 100644
--- a/src/evals/evaluate_continuation.py
+++ b/src/evals/evaluate_continuation.py
@@ -17,6 +17,7 @@ def valid_continuation(
     """
     Given a continuation as supplied by the model,
     return whether it is a valid integer or not.
+    If in biinary, the continuation will be prefixed with 0b.
     """
     try:
         # TODO: Work for arbitrary base continuation
@@ -25,7 +26,6 @@ def valid_continuation(
         if base == 10:
             int(model_continuation)
         elif base == 2:
-
             int(model_continuation[2:], 2)
     except ValueError:
         return False
diff --git a/src/evals/prompts/distribution_prompt.py b/src/evals/prompts/distribution_prompt.py
index 145c104..ae3940a 100644
--- a/src/evals/prompts/distribution_prompt.py
+++ b/src/evals/prompts/distribution_prompt.py
@@ -30,7 +30,7 @@ Do not include any additional commentary.
 SELF_EXPLANATION_PROMPT2 = (
 """In your opinion, what is the most likely function which generated the following sequence?
 Assume the first number was generated by f(0), the second by f(1), the third by f(2), and so on.
-The function should output the same number in the same representation as the sequence.
+The function should output numbers in the same representation as the sequence.
 Give your response in the format:
 Explanation: <function>
 """
@@ -105,6 +105,10 @@ DISTRIBUTIONS = {
         "continuation": SELF_CONTINUATION_PROMPT,
         "explanation": SELF_EXPLANATION_PROMPT,
     },
+    "default-change": {
+        "continuation": SELF_CONTINUATION_PROMPT2,
+        "explanation": SELF_EXPLANATION_PROMPT2,
+    },
     "self-simulation": {
         "continuation": SIMULATION_CONTINUATION_PROMPT,
         "explanation": SIMULATION_EXPLANATION_PROMPT,
diff --git a/src/evals/prompts/explanation_prompt.py b/src/evals/prompts/explanation_prompt.py
index 124357f..723e593 100644
--- a/src/evals/prompts/explanation_prompt.py
+++ b/src/evals/prompts/explanation_prompt.py
@@ -113,7 +113,7 @@ def generate_exp_shot_prompt(
     if shot_method == "random":
         fn, offset = _generate_random_function(sequence_functions, (0, 7), (0, 7))
         # Reformat fn to replace every x after the first with x+offset
-        fn = reformat_function(fn, offset)
+        fn = reformat_function(fn, offset, base)
         sequence = [eval(fn)(x) for x in range(sequence_length)]
     else:
         raise ValueError(f"Invalid shot method: {shot_method}")
@@ -129,10 +129,10 @@ def generate_exp_shot_prompt(
         return text
 
     elif model_name in OpenAIChatModels.list():
-        if base == 10:
+        if base == 10 or base == 2:
             q_text = ",".join([str(x) for x in sequence])
-        elif base == 2:
-            q_text = ",".join([bin(x) for x in sequence])
+        # elif base == 2:
+        #     q_text = ",".join([bin(x) for x in sequence])
         response = [{"role": "user", "content": q_text}]
         a_text = "Explanation: " + fn
         response += [{"role": "assistant", "content": a_text}]
diff --git a/src/evals/sequence_completion_with_base_change.py b/src/evals/sequence_completion_with_base_change.py
index 0ce0b8e..b51436b 100644
--- a/src/evals/sequence_completion_with_base_change.py
+++ b/src/evals/sequence_completion_with_base_change.py
@@ -37,7 +37,6 @@ def evaluate_compute_dependence_with_base_changes(
         results = {}
         all_data = []
         ambiguous_sequences = find_ambiguous_integer_sequences()
-        breakpoint()      
         for sequence in ambiguous_sequences:
             # turn the sequence from a string into a list of integers
             int_sequence = [int(x) for x in sequence.split(",")]
@@ -58,9 +57,10 @@ def evaluate_compute_dependence_with_base_changes(
                     )
                 except Exception as e:
                     logger.warning("Error in self consistency evaluation.")
-                    logger.error(f"Error is: {str(e)}")
+                    logger.error(str(e))
                 else:
                     total += 1
+                    breakpoint()
                     break
         else:
             pass
diff --git a/src/evals/utils.py b/src/evals/utils.py
index 9d49dd7..1ea5df0 100644
--- a/src/evals/utils.py
+++ b/src/evals/utils.py
@@ -66,7 +66,7 @@ def _generate_random_function(
     return (fn, offset)
 
 def reformat_function(
-    fn: str, offset: int
+    fn: str, offset: int, base: int = 10
 ) -> str:
     """
     Reformat a function to incorporate an offset, so the function is zero indexed.
@@ -80,6 +80,13 @@ def reformat_function(
     fn = fn.replace('x', replacement)
     # restore the first occurrence
     fn = fn.replace('<placeholder>', 'x', 1)
+
+    if base == 2:
+        # Wrap the output in a binary conversion
+        prefix, suffix = fn.split(":", 1)
+        # Add bin around the calculation part and join back together
+        fn = prefix + ": bin(" + suffix.strip() + ")"
+
     return fn
 
 def format_question(
diff --git a/src/tests/tests_q11.py b/src/tests/tests_q11.py
index 51fee45..71b3753 100644
--- a/src/tests/tests_q11.py
+++ b/src/tests/tests_q11.py
@@ -20,7 +20,7 @@ def test_completion_prompt():
 
 def test_create_continuation_prompt():
     sequence = [1, 2, 3, 4, 5, 6]
-    distribution = "default"
+    distribution = "default-change"
     model_name = "text-davinci-003"
     base = 2
     shots = 5
@@ -38,7 +38,7 @@ def test_create_continuation_prompt():
 
 def test_create_explanation_prompt():
     sequence = [1, 2, 3, 4, 5, 6]
-    distribution = "default"
+    distribution = "default-change"
     model_name = "gpt-3.5-turbo"
     base = 2
     shots = 5
@@ -78,4 +78,5 @@ def test_self_consistency_evaluation():
     print(outputs)
 
 if __name__ == "__main__":
-    test_self_consistency_evaluation()
+    # test_create_continuation_prompt()
+    test_create_explanation_prompt()
[2023-05-31 18:15:38,766][src.utils][INFO] - Changed directory to /Users/olejorgensen/Documents/AISC/introspective-self-consistency/results/2023-05-31-18-15-38/evaluate_compute_dependence_with_base_changes
[2023-05-31 18:15:40,866][src.evals.sequence_completion_with_base_change][INFO] - Total: 0
[2023-05-31 18:15:40,866][src.evals.sequence_completion_with_base_change][INFO] - Sequence: 0,1,2,0
[2023-05-31 18:15:40,866][src.evals.sequence_completion_with_base_change][INFO] - base be: 2
[2023-05-31 18:15:40,866][src.evals.prompts.continuation_prompt][INFO] - model name is: gpt-3.5-turbo
[2023-05-31 18:15:40,866][src.evals.prompts.continuation_prompt][INFO] - response is: [{'role': 'user', 'content': '0b1011011001000,0b11011000000000,0b110100101111000,0b1011011001000000'}, {'role': 'assistant', 'content': '0b10010000101101000'}]
[2023-05-31 18:15:40,866][src.evals.prompts.continuation_prompt][INFO] - model name is: gpt-3.5-turbo
[2023-05-31 18:15:40,866][src.evals.prompts.continuation_prompt][INFO] - response is: [{'role': 'user', 'content': '0b100100,0b101010,0b110000,0b110110'}, {'role': 'assistant', 'content': '0b111100'}]
[2023-05-31 18:15:40,866][src.evals.prompts.continuation_prompt][INFO] - model name is: gpt-3.5-turbo
[2023-05-31 18:15:40,866][src.evals.prompts.continuation_prompt][INFO] - response is: [{'role': 'user', 'content': '0b1,0b100,0b10,0b0'}, {'role': 'assistant', 'content': '0b11'}]
[2023-05-31 18:15:40,866][src.evals.prompts.continuation_prompt][INFO] - model name is: gpt-3.5-turbo
[2023-05-31 18:15:40,866][src.evals.prompts.continuation_prompt][INFO] - response is: [{'role': 'user', 'content': '0b110,0b1000,0b1010,0b1100'}, {'role': 'assistant', 'content': '0b1110'}]
[2023-05-31 18:15:40,867][src.evals.prompts.explanation_prompt][INFO] - [{'role': 'system', 'content': '\nHere are some examples of sequence explanations, i.e. python functions\nwhich generated the preceding sequences base 2. Assume the first number was generated by f(0),\nthe second by f(1), the third by f(2), and so on.\n'}, {'role': 'user', 'content': '0b1,0b1,0b1,0b1'}, {'role': 'assistant', 'content': 'Explanation: lambda x: bin(1 ** (1 * (x + 5)))'}, {'role': 'user', 'content': '0b1,0b10,0b11,0b101'}, {'role': 'assistant', 'content': 'Explanation: lambda x: bin([i for i in range(100) if i % (3 + 1) or i % (1 + 1)][(x + 0)])'}, {'role': 'user', 'content': '0b10000000000,0b1000000000000000,0b111100110000000000,0b100000000000000000000'}, {'role': 'assistant', 'content': 'Explanation: lambda x: bin((4 * (x + 1)) ** 5)'}, {'role': 'user', 'content': '0b10100,0b10111,0b11010,0b11101'}, {'role': 'assistant', 'content': 'Explanation: lambda x: bin((3 * (x + 5)) + 5)'}, {'role': 'user', 'content': '\nIn your opinion, what is the most likely function which generated the following sequence?\nAssume the first number was generated by f(0), the second by f(1), the third by f(2), and so on.\nThe function should output the number in decimal form.\nGive your response in the format:\nExplanation: <function>\n\nThe sequence is in base 2.\nQ: 0b0,0b1,0b10,0b0'}]
[2023-05-31 18:15:40,867][src.evals.check_self_consistency][INFO] - Generating a continuation and explanation
[2023-05-31 18:15:42,551][src.evals.check_self_consistency][INFO] - implied_sequence: [0, 1, 1, 0]
[2023-05-31 18:15:42,551][src.evals.check_self_consistency][INFO] - sequence: [0, 1, 2, 0]
[2023-05-31 18:15:42,551][src.evals.check_self_consistency][INFO] - implied_continuation: 1
[2023-05-31 18:15:42,551][src.evals.check_self_consistency][INFO] - continuation: 1
[2023-05-31 18:16:13,823][src.evals.sequence_completion_with_base_change][INFO] - Total: 1
[2023-05-31 18:16:14,510][src.evals.sequence_completion_with_base_change][INFO] - Sequence: 1,2,0,1
[2023-05-31 18:16:16,128][src.evals.sequence_completion_with_base_change][INFO] - base be: 2
[2023-05-31 18:16:19,323][src.evals.sequence_completion_with_base_change][WARNING] - Error in self consistency evaluation.
[2023-05-31 18:16:19,323][src.evals.sequence_completion_with_base_change][ERROR] - 
[2023-05-31 18:16:19,324][src.evals.sequence_completion_with_base_change][INFO] - base be: 2
[2023-05-31 18:16:19,324][src.evals.prompts.continuation_prompt][INFO] - model name is: gpt-3.5-turbo
[2023-05-31 18:16:19,324][src.evals.prompts.continuation_prompt][INFO] - response is: [{'role': 'user', 'content': '0b10,0b100,0b110,0b1000'}, {'role': 'assistant', 'content': '0b1010'}]
[2023-05-31 18:16:19,325][src.evals.prompts.continuation_prompt][INFO] - model name is: gpt-3.5-turbo
[2023-05-31 18:16:19,325][src.evals.prompts.continuation_prompt][INFO] - response is: [{'role': 'user', 'content': '0b1101,0b10010,0b10111,0b11100'}, {'role': 'assistant', 'content': '0b100001'}]
[2023-05-31 18:16:19,325][src.evals.prompts.continuation_prompt][INFO] - model name is: gpt-3.5-turbo
[2023-05-31 18:16:19,326][src.evals.prompts.continuation_prompt][INFO] - response is: [{'role': 'user', 'content': '0b10011,0b10110,0b11001,0b11100'}, {'role': 'assistant', 'content': '0b11111'}]
[2023-05-31 18:16:19,326][src.evals.prompts.continuation_prompt][INFO] - model name is: gpt-3.5-turbo
[2023-05-31 18:16:19,326][src.evals.prompts.continuation_prompt][INFO] - response is: [{'role': 'user', 'content': '0b0,0b11,0b110,0b1001'}, {'role': 'assistant', 'content': '0b1100'}]
[2023-05-31 18:16:19,327][src.evals.prompts.explanation_prompt][INFO] - [{'role': 'system', 'content': '\nHere are some examples of sequence explanations, i.e. python functions\nwhich generated the preceding sequences base 2. Assume the first number was generated by f(0),\nthe second by f(1), the third by f(2), and so on.\n'}, {'role': 'user', 'content': '0b1001,0b1010,0b1011,0b1100'}, {'role': 'assistant', 'content': 'Explanation: lambda x: bin((1 * (x + 5)) + 4)'}, {'role': 'user', 'content': '0b101,0b1001,0b1101,0b10001'}, {'role': 'assistant', 'content': 'Explanation: lambda x: bin((4 * (x + 1)) + 1)'}, {'role': 'user', 'content': '0b0,0b0,0b0,0b0'}, {'role': 'assistant', 'content': 'Explanation: lambda x: bin((0 * (x + 5)) * 2)'}, {'role': 'user', 'content': '0b0,0b1000,0b10000,0b11000'}, {'role': 'assistant', 'content': 'Explanation: lambda x: bin((2 * (x + 0)) * 4)'}, {'role': 'user', 'content': '\nIn your opinion, what is the most likely function which generated the following sequence?\nAssume the first number was generated by f(0), the second by f(1), the third by f(2), and so on.\nThe function should output the number in decimal form.\nGive your response in the format:\nExplanation: <function>\n\nThe sequence is in base 2.\nQ: 0b1,0b10,0b0,0b1'}]
[2023-05-31 18:16:19,327][src.evals.check_self_consistency][INFO] - Generating a continuation and explanation
[2023-05-31 18:16:21,296][src.evals.check_self_consistency][INFO] - implied_sequence: [True, 2, 0, True]
[2023-05-31 18:16:21,297][src.evals.check_self_consistency][INFO] - sequence: [1, 2, 0, 1]
[2023-05-31 18:16:21,297][src.evals.check_self_consistency][INFO] - implied_continuation: 2
[2023-05-31 18:16:21,297][src.evals.check_self_consistency][INFO] - continuation: 2
[2023-05-31 18:16:24,883][__main__][ERROR] - 
Traceback (most recent call last):
  File "/Users/olejorgensen/Documents/AISC/introspective-self-consistency/src/utils.py", line 58, in decorated
    return func(*args, **kwargs)
  File "/Users/olejorgensen/Documents/AISC/introspective-self-consistency/main.py", line 36, in main
    evaluate_compute_dependence_with_base_changes(
  File "/Users/olejorgensen/Documents/AISC/introspective-self-consistency/src/utils.py", line 42, in wrapped
    return func(*args, **kwargs)
  File "/Users/olejorgensen/Documents/AISC/introspective-self-consistency/src/evals/sequence_completion_with_base_change.py", line 64, in evaluate_compute_dependence_with_base_changes
    break
  File "/Users/olejorgensen/Documents/AISC/introspective-self-consistency/src/evals/sequence_completion_with_base_change.py", line 64, in evaluate_compute_dependence_with_base_changes
    break
  File "/Users/olejorgensen/miniconda3/envs/aisc-env2/lib/python3.10/bdb.py", line 90, in trace_dispatch
    return self.dispatch_line(frame)
  File "/Users/olejorgensen/miniconda3/envs/aisc-env2/lib/python3.10/bdb.py", line 115, in dispatch_line
    if self.quitting: raise BdbQuit
bdb.BdbQuit
