[2023-05-26 11:15:15,882][src.utils][INFO] - Git sha: 801edc7a631335386ba3c9413a1e5c6be97303f7
[2023-05-26 11:15:15,894][src.utils][INFO] - Changed files: ['conf/tasks/compute_dependence_with_base_changes.yaml', 'src/evals/evaluate_continuation.py', 'src/evals/evaluate_explanation.py', 'src/evals/prompts/continuation_prompt.py', 'src/evals/sequence_completion_with_base_change.py', 'src/models/openai_model.py']
[2023-05-26 11:15:15,903][src.utils][INFO] - Git diff:
diff --git a/conf/tasks/compute_dependence_with_base_changes.yaml b/conf/tasks/compute_dependence_with_base_changes.yaml
index 29b202c..6be90fc 100644
--- a/conf/tasks/compute_dependence_with_base_changes.yaml
+++ b/conf/tasks/compute_dependence_with_base_changes.yaml
@@ -1,7 +1,7 @@
 sequence_type: binary
-model: gpt-3.5-turbo
+model: gpt-4-0314
 num_shots: 4
 on_ambiguous_sequences: true
 num_samples: 1
-distribution: forced-consistency
+distribution: default
 shot_method: random
diff --git a/src/evals/evaluate_continuation.py b/src/evals/evaluate_continuation.py
index 65788a6..e1f7f45 100644
--- a/src/evals/evaluate_continuation.py
+++ b/src/evals/evaluate_continuation.py
@@ -7,6 +7,8 @@ from src.models.openai_model import (
     generate_completion,
 )
 
+from src.models.openai_model import OpenAITextModels, OpenAIChatModels
+
 
 def valid_continuation(
     model_continuation: str,
@@ -23,6 +25,7 @@ def valid_continuation(
         if base == 10:
             int(model_continuation)
         elif base == 2:
+
             int(model_continuation[2:], 2)
     except ValueError:
         return False
@@ -38,7 +41,7 @@ def generate_continuation(
     """
     Given a prompt, generate a continuation from the model.
     """
-    if model_name == "text-davinci-003":
+    if model_name in OpenAITextModels.list():
         # Feed this into the model
         model_response = generate_completion(
             prompt=prompt,
@@ -46,7 +49,7 @@ def generate_continuation(
             max_tokens=256,
             model=DAVINCI_MODEL_NAME,
         )
-    elif model_name == "gpt-3.5-turbo":
+    elif model_name in OpenAIChatModels.list():
         # Feed this into the model
         model_response = generate_chat_completion(
             prompt_turns=prompt,
diff --git a/src/evals/evaluate_explanation.py b/src/evals/evaluate_explanation.py
index e1f12d4..ff3071f 100644
--- a/src/evals/evaluate_explanation.py
+++ b/src/evals/evaluate_explanation.py
@@ -7,6 +7,8 @@ from src.models.openai_model import (
     generate_completion,
 )
 
+from src.models.openai_model import OpenAITextModels, OpenAIChatModels
+
 
 def valid_explanation(
     fn_form: str,
@@ -55,7 +57,7 @@ def generate_explanation(
     Given a prompt, generate an explanation from the model.
     TODO: refactor code, entirely copied from generate_continuation
     """
-    if model_name == "text-davinci-003":
+    if model_name in OpenAITextModels.list():
         # Feed this into the model
         model_response = generate_completion(
             prompt=prompt,
@@ -63,7 +65,7 @@ def generate_explanation(
             max_tokens=256,
             model=DAVINCI_MODEL_NAME,
         )
-    elif model_name == "gpt-3.5-turbo":
+    elif model_name in OpenAIChatModels.list():
         # Feed this into the model
         model_response = generate_chat_completion(
             prompt_turns=prompt,
diff --git a/src/evals/prompts/continuation_prompt.py b/src/evals/prompts/continuation_prompt.py
index ec802ba..ad14e39 100644
--- a/src/evals/prompts/continuation_prompt.py
+++ b/src/evals/prompts/continuation_prompt.py
@@ -27,6 +27,7 @@ The sequences will be taken from the list of ambiguous sequences.
 # import random
 from typing import List, Union
 
+from src.models.openai_model import OpenAITextModels, OpenAIChatModels
 from src.evals.prompts.distribution_prompt import DISTRIBUTIONS
 from src.evals.utils import _generate_random_function, reformat_function
 
@@ -74,7 +75,7 @@ def create_continuation_prompt(
         text += ",".join([bin(x) for x in sequence])
     else:
         raise ValueError(f"Invalid base: {base}")
-    if model_name == "text-davinci-003":
+    if model_name in OpenAITextModels.list():
         # Prepend to the shots
         pretext = "Here are some examples of sequence continuations."
         pretext += "\n"
@@ -82,7 +83,7 @@ def create_continuation_prompt(
         text += "\n"
         text += "A: "
         return text
-    elif model_name == "gpt-3.5-turbo":
+    elif model_name in OpenAIChatModels.list():
         pretext = [
             {
                 "role": "system",
@@ -108,8 +109,8 @@ def generate_cont_shot_prompt(
         sequence = [eval(fn)(x) for x in range(sequence_length)]
     else:
         raise ValueError(f"Invalid shot method: {shot_method}")
-
-    if model_name == "text-davinci-003":
+    print("model name is: ", model_name)
+    if model_name in OpenAITextModels.list():
         text = "Q: "
         if base == 10:
             text += ",".join([str(x) for x in sequence])
@@ -123,7 +124,7 @@ def generate_cont_shot_prompt(
         text += "\n"
         return text
 
-    elif model_name == "gpt-3.5-turbo":
+    elif model_name in OpenAIChatModels.list():
         if base == 10:
             q_text = ",".join([str(x) for x in sequence])
             a_text = str(eval(fn)(sequence_length))
diff --git a/src/evals/sequence_completion_with_base_change.py b/src/evals/sequence_completion_with_base_change.py
index 24f2112..84b69d8 100644
--- a/src/evals/sequence_completion_with_base_change.py
+++ b/src/evals/sequence_completion_with_base_change.py
@@ -61,7 +61,7 @@ def evaluate_compute_dependence_with_base_changes(
                     )
                 except Exception as e:
                     print("oopies")
-                    print(e)
+                    raise e
                 else:
                     if sequence in results:
                         results[sequence][
diff --git a/src/models/openai_model.py b/src/models/openai_model.py
index 6c18f7e..2cb9245 100644
--- a/src/models/openai_model.py
+++ b/src/models/openai_model.py
@@ -6,6 +6,8 @@ from typing import List, Union
 
 import openai
 
+from src.models.utils import INVALID_RESPONSE, ExtendedEnum
+
 CHAT_PROMPT_TEMPLATE = {"role": "user", "content": ""}
 # TEXT_PROMPT_TEMPLATE is just a simple string or array of strings
 DAVINCI_MODEL_NAME = "text-davinci-003"
@@ -16,11 +18,11 @@ INVALID_RESPONSE = "INVALID_RESPONSE"
 openai.api_key = os.getenv("OPENAI_API_KEY")
 
 
-class OpenAITextModels(Enum):
+class OpenAITextModels(ExtendedEnum):
     TEXT_DAVINCI_003 = "text-davinci-003"
 
 
-class OpenAIChatModels(Enum):
+class OpenAIChatModels(ExtendedEnum):
     CHAT_GPT_35 = "gpt-3.5-turbo"
     CHAT_GPT_4 = "gpt-4-0314"
 
[2023-05-26 11:15:17,152][__main__][ERROR] - Invalid model name: gpt-4-0314
Traceback (most recent call last):
  File "/Users/olejorgensen/Documents/AISC/introspective-self-consistency/src/utils.py", line 58, in decorated
    return func(*args, **kwargs)
  File "/Users/olejorgensen/Documents/AISC/introspective-self-consistency/main.py", line 36, in main
    evaluate_compute_dependence_with_base_changes(
  File "/Users/olejorgensen/Documents/AISC/introspective-self-consistency/src/evals/sequence_completion_with_base_change.py", line 64, in evaluate_compute_dependence_with_base_changes
    raise e
  File "/Users/olejorgensen/Documents/AISC/introspective-self-consistency/src/evals/sequence_completion_with_base_change.py", line 52, in evaluate_compute_dependence_with_base_changes
    ) = self_consistency_evaluation(
  File "/Users/olejorgensen/Documents/AISC/introspective-self-consistency/src/evals/check_self_consistency.py", line 49, in self_consistency_evaluation
    explanation_prompt = create_explanation_prompt(
  File "/Users/olejorgensen/Documents/AISC/introspective-self-consistency/src/evals/prompts/explanation_prompt.py", line 61, in create_explanation_prompt
    shot_prompt = generate_exp_shot_prompt(
  File "/Users/olejorgensen/Documents/AISC/introspective-self-consistency/src/evals/prompts/explanation_prompt.py", line 135, in generate_exp_shot_prompt
    raise ValueError(f"Invalid model name: {model_name}")
ValueError: Invalid model name: gpt-4-0314
