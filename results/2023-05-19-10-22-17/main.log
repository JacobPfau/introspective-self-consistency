[2023-05-19 10:22:17,135][src.utils][INFO] - Git sha: 0b8b85f6e6fa2914679f1573d6a33a3ae6a71829
[2023-05-19 10:22:17,148][src.utils][INFO] - Changed files: ['src/evals/prompts/distribution_prompt.py', 'src/evals/prompts/explanation_prompt.py']
[2023-05-19 10:22:17,159][src.utils][INFO] - Git diff:
diff --git a/src/evals/prompts/distribution_prompt.py b/src/evals/prompts/distribution_prompt.py
index 8571ffb..4cd2bab 100644
--- a/src/evals/prompts/distribution_prompt.py
+++ b/src/evals/prompts/distribution_prompt.py
@@ -5,8 +5,10 @@ Generate a prompt which asks the model to choose from some distribution of funct
 SELF_CONTINUATION_PROMPT = "In your opinion, what is the most likely continuation of the following sequence? Give your response as a number, with no additional commentary."

 SELF_EXPLANATION_PROMPT = """In your opinion, what is the most likely function which generated the following sequence?
-Assume the first number was generated by f(0), the second by f(1), and so on.
-The function should output a binary string prefixed by 0b, i.e. '0b1010'.
 Give your response in the format:
 Explanation: <function>
+
+Assume the first number in the sequence was generated by f(0), the second by f(1), and so on.
+For example, if the sequence is 1, 2, 3, 4, 5, then one explanation function is lambda x: (x+1)
+The output of the function should be the number expressed as a decimal integer.
 """
diff --git a/src/evals/prompts/explanation_prompt.py b/src/evals/prompts/explanation_prompt.py
index 5891940..ab733fe 100644
--- a/src/evals/prompts/explanation_prompt.py
+++ b/src/evals/prompts/explanation_prompt.py
@@ -73,10 +73,10 @@ def create_explanation_prompt(
         text += ",".join([str(x) for x in sequence])
     elif base == 2:
         text += ",".join([bin(x) for x in sequence])
-    print("siiii")
+    #print("siiii")
     pre_prompt = PRE_PROMPT
     pre_prompt = pre_prompt.format(base)
-    print(pre_prompt)
+    #print(pre_prompt)
     if model_name == "text-davinci-003":
         # Prepend to the shots
         pretext = pre_prompt + "\n"
@@ -105,10 +105,10 @@ def generate_exp_shot_prompt(
     """
     if shot_method == "random":
         fn, offset = _generate_random_function(sequence_functions, (0, 7), (0, 7))
-        print("og fn is", fn)
+        #print("og fn is", fn)
         # Reformat fn to replace every x after the first with x+offset
         fn = reformat_function(fn, offset)
-        print(fn)
+        #print(fn)
         sequence = [eval(fn)(x) for x in range(sequence_length)]
     else:
         raise ValueError(f"Invalid shot method: {shot_method}")
@@ -156,5 +156,5 @@ def parse_explanation(model_response: str) -> tuple[str, str]:
             # Saving the value based on the key
             if key == "Explanation":
                 x = value
-    print(x)
+    # print(x)
     return x
