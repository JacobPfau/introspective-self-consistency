[2023-05-18 18:50:31,417][src.utils][INFO] - Git sha: d998e606faf3df67a9e43b73cde0e5edd0d1d02b
[2023-05-18 18:50:31,429][src.utils][INFO] - Changed files: ['src/evals/check_self_consistency.py', 'src/evals/evaluate_explanation.py', 'src/evals/prompts/continuation_prompt.py', 'src/evals/prompts/distribution_prompt.py', 'src/evals/prompts/explanation_prompt.py', 'src/evals/utils.py', 'src/tests/tests_q11.py']
[2023-05-18 18:50:31,441][src.utils][INFO] - Git diff:
diff --git a/src/evals/check_self_consistency.py b/src/evals/check_self_consistency.py
index c241061..850af02 100644
--- a/src/evals/check_self_consistency.py
+++ b/src/evals/check_self_consistency.py
@@ -62,6 +62,8 @@ def self_consistency_evaluation(
             model_name=model_name,
             temperature=temperature,
         )
+        # strip whitespace
+        continuation = continuation.strip()
 
         if not valid_continuation(continuation, base):
             print("invalid continuation: ", continuation)
@@ -82,14 +84,12 @@ def self_consistency_evaluation(
 
         # Parse explanation
         try:
-            fn, offset = parse_explanation(explanation)
+            fn = parse_explanation(explanation)
         except:
             invalid_responses += 1
             continue
 
-        offset = int(offset)
-
-        if not valid_explanation(fn, offset, len(sequence)):
+        if not valid_explanation(fn, len(sequence)):
             print("invalid explanation: ", explanation)
             invalid_responses += 1
             continue
@@ -97,13 +97,11 @@ def self_consistency_evaluation(
             # check if the explanation is valid up to the continuation
             implied_sequence = generate_implied_sequence(
                 fn_form=fn,
-                offset=offset,
                 sequence_length=len(sequence),
             )
 
             implied_continuation = generate_implied_continuation(
                 fn_form=fn,
-                offset=offset,
                 sequence_length=len(sequence),
             )
 
diff --git a/src/evals/evaluate_explanation.py b/src/evals/evaluate_explanation.py
index 4fd6026..e2e5503 100644
--- a/src/evals/evaluate_explanation.py
+++ b/src/evals/evaluate_explanation.py
@@ -10,7 +10,6 @@ from src.models.openai_model import (
 
 def valid_explanation(
     fn_form: str,
-    offset: int,
     sequence_length: int,
 ) -> bool:
     """
@@ -19,7 +18,7 @@ def valid_explanation(
     """
     try:
         # TODO: need to have this work for an arbitrary number of arguments
-        [eval(fn_form.format(i + offset)) for i in range(sequence_length + 1)]
+        [eval(fn_form.format(i)) for i in range(sequence_length + 1)]
     except SyntaxError:
         return False
     except NameError:
@@ -82,23 +81,21 @@ def generate_explanation(
 
 def generate_implied_sequence(
     fn_form: str,
-    offset: int,
     sequence_length: int,
 ) -> List[int]:
     """
     Given a function form and an offset as supplied by the model,
     generate the sequence.
     """
-    return [eval(fn_form)(i + offset) for i in range(sequence_length)]
+    return [eval(fn_form)(i) for i in range(sequence_length)]
 
 
 def generate_implied_continuation(
     fn_form: str,
-    offset: int,
     sequence_length: int,
 ) -> int:
     """
     Given a function form and an offset as supplied by the model,
     generate the next element of the sequence.
     """
-    return eval(fn_form)(offset + sequence_length)
+    return eval(fn_form)(sequence_length)
diff --git a/src/evals/prompts/continuation_prompt.py b/src/evals/prompts/continuation_prompt.py
index d720130..fc35b63 100644
--- a/src/evals/prompts/continuation_prompt.py
+++ b/src/evals/prompts/continuation_prompt.py
@@ -21,18 +21,16 @@ Prompts will take the form:
     For (text) explanations, this will be of the form:
 --------------------------
     Here are some examples of sequence explanations, i.e. python functions
-    which could have generated the preceding sequences, with associated offset.
+    which could have generated the preceding sequences. Assume the first
+    number was generated by f(0), the second by f(1), and so on.
     Sequence: 2, 4, 6
-    Explanation: lambda x: 2*x
-    Offset: 0
+    Explanation: lambda x: 2*(x+1)
 
     Sequence: 1, 2, 3, 4, 5
-    Explanation: lambda x: x
-    Offset: 1
+    Explanation: lambda x: (x+1)
 
     Sequence: 9, 16, 25, 36
-    Explanation: lambda x: x**2
-    Offset: 3
+    Explanation: lambda x: (x+3)**2
 
     ***EXPLANATION_PROMPT***
 
@@ -48,7 +46,7 @@ The sequences will be taken from the list of ambiguous sequences.
 # import random
 from typing import List, Union
 
-from src.evals.utils import _generate_random_function
+from src.evals.utils import _generate_random_function, reformat_function
 
 # from evals.utils import _generate_random_function, generate_wrong_functions
 from src.pipelines.sequence_completions import sequence_functions
@@ -59,6 +57,8 @@ from src.evals.prompts.distributions import DISTRIBUTIONS
 #     sequence_functions,
 # )
 
+# TODO: fix generating functions to include recursive progressions, an ok fix for now.
+del sequence_functions["recursive_progression"]
 
 def create_continuation_prompt(
     sequence: List[int],
@@ -77,7 +77,7 @@ def create_continuation_prompt(
         for i in range(shots):
             # Note: we are using the sequence length implicitly specified by
             # the target sequence to generate the prompts.
-            shot_prompt = generate_cont_shot_prompt(shot_method, sequence_length, model_name)
+            shot_prompt = generate_cont_shot_prompt(shot_method, sequence_length, model_name, base)
             prompt_text += shot_prompt
 
     # TODO: Need to fix!!
@@ -121,7 +121,9 @@ def generate_cont_shot_prompt(
     """
     if shot_method == "random":
         fn, offset = _generate_random_function(sequence_functions, (0, 7), (0, 7))
-        sequence = [eval(fn)(x + offset) for x in range(sequence_length)]
+        # replace 
+        fn = reformat_function(fn, offset)
+        sequence = [eval(fn)(x) for x in range(sequence_length)]
     else:
         raise ValueError(f"Invalid shot method: {shot_method}")
 
@@ -129,10 +131,10 @@ def generate_cont_shot_prompt(
         text = "Q: "
         if base == 10:
             text += ",".join([str(x) for x in sequence])
-            a_text = str(eval(fn)(sequence_length + offset))
+            a_text = str(eval(fn)(sequence_length))
         elif base == 2:
             text += ",".join([bin(x) for x in sequence])
-            a_text = bin(eval(fn)(sequence_length + offset))
+            a_text = bin(eval(fn)(sequence_length))
         text += "\n"
         text += "A: "
         text += a_text
@@ -142,10 +144,10 @@ def generate_cont_shot_prompt(
     elif model_name == "gpt-3.5-turbo":
         if base == 10:
             q_text = ",".join([str(x) for x in sequence])
-            a_text = str(eval(fn)(sequence_length + offset))
+            a_text = str(eval(fn)(sequence_length))
         elif base == 2:
             q_text = ",".join([bin(x) for x in sequence])
-            a_text = bin(eval(fn)(sequence_length + offset))
+            a_text = bin(eval(fn)(sequence_length))
         response = [{"role": "user", "content": q_text}]
         response += [{"role": "assistant", "content": a_text}]
         # print("responseo be: ", response)
diff --git a/src/evals/prompts/distribution_prompt.py b/src/evals/prompts/distribution_prompt.py
index 9c0dd61..2875bab 100644
--- a/src/evals/prompts/distribution_prompt.py
+++ b/src/evals/prompts/distribution_prompt.py
@@ -6,8 +6,8 @@ SELF_CONTINUATION_PROMPT = (
     "In your opinion, what is the most likely continuation of the following sequence? Give your response as a number, with no additional commentary."
 )
 
-SELF_EXPLANATION_PROMPT = """In your opinion, what is the most likely explanation for how the following sequence was generated?
+SELF_EXPLANATION_PROMPT = """In your opinion, what is the most likely function which generated the following sequence?
+Assume the first number was generated by f(0), the second by f(1), and so on.
 Give your response in the format:
 Explanation: <function>
-Offset: <offset>
 """
diff --git a/src/evals/prompts/explanation_prompt.py b/src/evals/prompts/explanation_prompt.py
index 665964b..0d13a0c 100644
--- a/src/evals/prompts/explanation_prompt.py
+++ b/src/evals/prompts/explanation_prompt.py
@@ -4,18 +4,16 @@ Create a prompt to continue a sequence of numbers, in an arbitrary base.
 Prompts will take the form:
 --------------------------
     Here are some examples of sequence explanations, i.e. python functions
-    which could have generated the preceding sequences, with associated offset.
+    which could have generated the preceding sequences. Assume the first
+    number was generated by f(0), the second by f(1), and so on.
     Sequence: 2, 4, 6
-    Explanation: lambda x: 2*x
-    Offset: 0
+    Explanation: lambda x: 2*(x+1)
 
     Sequence: 1, 2, 3, 4, 5
-    Explanation: lambda x: x
-    Offset: 1
+    Explanation: lambda x: (x+1)
 
     Sequence: 9, 16, 25, 36
-    Explanation: lambda x: x**2
-    Offset: 3
+    Explanation: lambda x: (x+3)**2
 
     ***EXPLANATION_PROMPT***
 
@@ -26,13 +24,23 @@ Prompts will take the form:
 
 from typing import List, Union
 
-from src.evals.utils import _generate_random_function
+from src.evals.utils import _generate_random_function, reformat_function
 
 # from evals.utils import _generate_random_function, generate_wrong_functions
 from src.models.openai_model import DAVINCI_MODEL_NAME
 from src.pipelines.sequence_completions import sequence_functions
 from src.evals.prompts.distributions import DISTRIBUTIONS
 
+PRE_PROMPT = (
+"""
+Here are some examples of sequence explanations, i.e. python functions 
+which generated the preceding sequences base {}. Assume the first number was generated by f(0),
+the second by f(1), and so on.
+"""
+)
+
+# TODO: fix generating functions to include recursive progressions, an ok fix for now.
+sequence_functions = sequence_functions.copy()
 
 def create_explanation_prompt(
     sequence: List[int],
@@ -60,11 +68,14 @@ def create_explanation_prompt(
     text += "\n"
     text += f"The sequence is in base {base}."
     text += "\nQ: "
-    text += ",".join([str(x) for x in sequence])
-    pre_prompt = (
-        """Here are some examples of sequence explanations, i.e. python functions 
-    which could have generated the preceding sequences, with associated offset."""
-    )
+    if base == 10:
+        text += ",".join([str(x) for x in sequence])
+    elif base == 2:
+        text += ",".join([bin(x) for x in sequence])
+    print("siiii")
+    pre_prompt = PRE_PROMPT
+    pre_prompt = pre_prompt.format(base)
+    print(pre_prompt)
     if model_name == "text-davinci-003":
         # Prepend to the shots
         pretext = pre_prompt + "\n"
@@ -93,7 +104,11 @@ def generate_exp_shot_prompt(
     """
     if shot_method == "random":
         fn, offset = _generate_random_function(sequence_functions, (0, 7), (0, 7))
-        sequence = [eval(fn)(x + offset) for x in range(sequence_length)]
+        print("og fn is", fn)
+        # Reformat fn to replace every x after the first with x+offset
+        fn = reformat_function(fn, offset)
+        print(fn)
+        sequence = [eval(fn)(x) for x in range(sequence_length)]
     else:
         raise ValueError(f"Invalid shot method: {shot_method}")
 
@@ -104,9 +119,6 @@ def generate_exp_shot_prompt(
         text += "Explanation: "
         text += fn
         text += "\n"
-        text += "Offset: "
-        text += str(offset)
-        text += "\n"
         return text
 
     elif model_name == "gpt-3.5-turbo":
@@ -116,8 +128,6 @@ def generate_exp_shot_prompt(
             q_text = ",".join([bin(x) for x in sequence])
         response = [{"role": "user", "content": q_text}]
         a_text = "Explanation: " + fn
-        a_text += "\n"
-        a_text += "Offset: " + str(offset)
         response += [{"role": "assistant", "content": a_text}]
         return response
 
@@ -127,14 +137,13 @@ def generate_exp_shot_prompt(
 
 def parse_explanation(model_response: str) -> tuple[str, str]:
     """
-    Parse an explanation into a function and offset.
+    Parse an explanation into a function.
     """
     # Splitting the string into lines
     lines = model_response.split('\n')
 
     # Initializing the variables with None
     x = ""
-    y = ""
 
     # Looping over the lines
     for line in lines:
@@ -145,7 +154,5 @@ def parse_explanation(model_response: str) -> tuple[str, str]:
             # Saving the value based on the key
             if key == 'Explanation':
                 x = value
-            elif key == 'Offset':
-                y = value
-    print(x, y)
-    return x, y
+    print(x)
+    return x
diff --git a/src/evals/utils.py b/src/evals/utils.py
index 8fad17d..9d49dd7 100644
--- a/src/evals/utils.py
+++ b/src/evals/utils.py
@@ -4,6 +4,7 @@ from typing import Dict, List, Tuple, Union
 
 from src.models.openai_model import (
     DAVINCI_MODEL_NAME,
+    CHAT_MODEL_NAME,
     generate_chat_completion,
     generate_completion,
 )
@@ -64,6 +65,22 @@ def _generate_random_function(
     offset = random.choice(list(range(offset_range[0], offset_range[1])))
     return (fn, offset)
 
+def reformat_function(
+    fn: str, offset: int
+) -> str:
+    """
+    Reformat a function to incorporate an offset, so the function is zero indexed.
+    """
+    first_occurrence = fn.find('x')
+    replacement = f'(x + {offset})'
+    if first_occurrence != -1:
+        fn = fn[:first_occurrence] + '<placeholder>' + fn[first_occurrence + len('x'):]
+
+    # replace all occurrences of x
+    fn = fn.replace('x', replacement)
+    # restore the first occurrence
+    fn = fn.replace('<placeholder>', 'x', 1)
+    return fn
 
 def format_question(
     prompt: Union[str, List[Dict[str, str]]],
diff --git a/src/tests/tests_q11.py b/src/tests/tests_q11.py
index a036b58..51fee45 100644
--- a/src/tests/tests_q11.py
+++ b/src/tests/tests_q11.py
@@ -55,11 +55,11 @@ def test_create_explanation_prompt():
 
 
 def test_self_consistency_evaluation():
-    model_name = "text-davinci-003"
+    model_name = "gpt-3.5-turbo"
     sequence = [1, 2, 3]
     distribution = "default"
     base = 2
-    shots = 4
+    shots = 16
     shot_method = "random"
     temperature = 0
     samples = 4
@@ -77,6 +77,5 @@ def test_self_consistency_evaluation():
 
     print(outputs)
 
-
 if __name__ == "__main__":
     test_self_consistency_evaluation()
