{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514d264c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "\n",
    "models = [\n",
    "    \"gpt-3.5-turbo\", \"gpt-4-0314\", \"text-davinci-003\"\n",
    "]\n",
    "runs = [\n",
    "    'final_run_2','final_run_3', 'final_run_4'\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d4873d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "total_sequences = 225\n",
    "consistency_results = []\n",
    "for answer_validity in ['valid', 'all']:\n",
    "    for model in models:\n",
    "        for run in runs:\n",
    "            df = pd.read_csv(\n",
    "                    f'./consistency/{run}/compute_dependence_with_base_changes=False,sequence_completion_capability=False,sequence_completion_equality.model={model},string_transformation_completion_equality=False/evaluate_sequence_completion_equality/sequence_completion_equality_evaluation_{model}.csv'\n",
    "            )\n",
    "\n",
    "            match_accs, model_match_accs, model_consistency_accs, consistent_and_matched_positive, consistent_and_matched_negative = (\n",
    "                [],\n",
    "                [],\n",
    "                [],\n",
    "                [],\n",
    "                []\n",
    "            )\n",
    "            match_accs_self_consistent = []\n",
    "\n",
    "\n",
    "            for i, data in df.iterrows():\n",
    "                match_accs.append(1 if data[\"generated_completion_matches\"] == True else 0)\n",
    "                match_accs_self_consistent.append(1\n",
    "                        if data[\"model_self_consistency_evaluation\"].strip() == \"Y\"\n",
    "                        else 0)\n",
    "\n",
    "            for i, data in df.iterrows():\n",
    "                model_match_accs.append(1 if data[\"model_completion_matches\"] == True else 0)\n",
    "\n",
    "            for i, data in df.iterrows():\n",
    "                if answer_validity == 'valid' and data[\"model_self_consistency_evaluation\"].strip() != \"Y\" and data[\"model_self_consistency_evaluation\"].strip() != \"N\":\n",
    "                    continue\n",
    "                model_consistency_accs.append(\n",
    "                    1 if data[\"model_self_consistency_evaluation\"].strip() == \"Y\" else 0\n",
    "                )\n",
    "\n",
    "            for i, data in df.iterrows():\n",
    "                if answer_validity == 'valid' and data[\"model_self_consistency_evaluation\"].strip() != \"Y\" and data[\"model_self_consistency_evaluation\"].strip() != \"N\":\n",
    "                    continue\n",
    "                if data[\"generated_completion_matches\"]:\n",
    "                    consistent_and_matched_positive.append(\n",
    "                        1\n",
    "                        if data[\"model_self_consistency_evaluation\"].strip() == \"Y\"\n",
    "                        else 0\n",
    "                    )\n",
    "                else:\n",
    "                    consistent_and_matched_negative.append(\n",
    "                        1\n",
    "                        if data[\"model_self_consistency_evaluation\"].strip() == \"N\"\n",
    "                        else 0\n",
    "                    )\n",
    "\n",
    "\n",
    "\n",
    "            ground_truth_consistent = np.mean(match_accs)\n",
    "            self_rule_following_consistency = np.mean(model_match_accs)\n",
    "            self_comparison_consistency = np.mean(model_consistency_accs)\n",
    "            consistent_and_matched_positive_acc = np.mean(consistent_and_matched_positive)\n",
    "            consistent_and_matched_negative_acc = np.mean(consistent_and_matched_negative)\n",
    "            self_consistency_precision = metrics.precision_score(match_accs, match_accs_self_consistent)\n",
    "            self_consistency_recall = metrics.recall_score(match_accs, match_accs_self_consistent)\n",
    "            self_consistency_f1 = metrics.f1_score(match_accs, match_accs_self_consistent)\n",
    "            print(\n",
    "                f\"\"\"\n",
    "                For {run} run {model} including {answer_validity} answers\n",
    "                Evaluated {len(df)} ambiguous sequences of {total_sequences} total.\n",
    "                Resulting in:\n",
    "                - {ground_truth_consistent}% ground-truth-consistent (using {len(match_accs)})\n",
    "                - {self_rule_following_consistency}% self-rule-following-consistency (using {len(model_match_accs)})\n",
    "                - {self_comparison_consistency}% self-comparison-consistency (using {len(model_consistency_accs)})\n",
    "                - {consistent_and_matched_positive_acc}% self-comparison-consistency==Y and ground-truth-consistent. (using {len(consistent_and_matched_positive)})\n",
    "                - {consistent_and_matched_negative_acc}% self-comparison-consistency==N and not ground-truth-consistent. (using {len(consistent_and_matched_negative)})\n",
    "                - {self_consistency_precision} precision\n",
    "                - {self_consistency_recall} recall\n",
    "                - {self_consistency_f1} f1\n",
    "                \"\"\"\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "            consistency_results.append({\n",
    "                \"model\": model,\n",
    "                \"run\": run,\n",
    "                \"answer_validity\": answer_validity,\n",
    "                \"ground_truth_consistent\": round(ground_truth_consistent * 100, 2),\n",
    "                \"ground_truth_consistent_num\": len(match_accs),\n",
    "                \"self_rule_following_consistency\":  round(self_rule_following_consistency * 100, 2),\n",
    "                \"self_rule_following_consistency_len\": len(model_match_accs),\n",
    "                \"self_comparison_consistency\": round(self_comparison_consistency * 100, 2),\n",
    "                \"self_comparison_consistency_len\": len(model_consistency_accs),\n",
    "                \"consistent_and_matched_positive\": round(consistent_and_matched_positive_acc * 100, 2),\n",
    "                \"consistent_and_matched_positive_len\": len(consistent_and_matched_positive),\n",
    "                \"consistent_and_matched_negative\": round(consistent_and_matched_negative_acc * 100, 2),\n",
    "                \"consistent_and_matched_negative_len\": len(consistent_and_matched_negative),\n",
    "                \"self_consistency_precision\": self_consistency_precision,\n",
    "                \"self_consistency_recall\": self_consistency_recall,\n",
    "                \"self_consistency_f1\": self_consistency_f1,\n",
    "            })\n",
    "\n",
    "consistency_df = pd.DataFrame(consistency_results)\n",
    "consistency_df.to_csv('./q0_consistency_results_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0729e90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_1 = consistency_df[['model', 'run', 'ground_truth_consistent']].rename(columns={'ground_truth_consistent': 'score'})\n",
    "new_df_1['score_type'] = 'Ground truth consistent'\n",
    "new_df_2 = consistency_df[['model', 'run', 'self_rule_following_consistency']].rename(columns={'self_rule_following_consistency': 'score'})\n",
    "new_df_2['score_type'] = 'Self-rule following consistency'\n",
    "new_df_3 = consistency_df[['model', 'run', 'self_comparison_consistency']].rename(columns={'self_comparison_consistency': 'score'})\n",
    "new_df_3['score_type'] = 'Self comparison consistency'\n",
    "\n",
    "new_df = pd.concat([new_df_1, new_df_2, new_df_3])\n",
    "new_df = new_df.sort_values(by=['run', 'score']).rename(columns={'run': 'sequence length', 'score_type': 'Consistency measure'})\n",
    "new_df['sequence length'] = new_df['sequence length'].apply(lambda x: x.split('_')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db05dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb68af41",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = new_df[new_df['Consistency measure'] != 'Self-rule following consistency']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27c1d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.catplot(x=\"model\", y=\"score\", col=\"sequence length\", hue=\"Consistency measure\", data=new_df, kind=\"bar\")\n",
    "ax.set(ylabel='Consistency', xlabel = '')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1b7d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "models = [\n",
    "    \"davinci\", \"gpt-3.5-turbo\", \"gpt-4-0314\", \"text-davinci-003\"\n",
    "]\n",
    "runs = [\n",
    "    'run_1', 'run_2', 'run_3'\n",
    "]\n",
    "total_sequences = 139\n",
    "capability_results = []\n",
    "for model in models:\n",
    "    for run in runs:\n",
    "        df = pd.read_csv(\n",
    "                f'./capability/{run}/compute_dependence_with_base_changes=False,sequence_completion_capability.model={model},sequence_completion_equality=False,string_transformation_completion_equality=False/evaluate_sequence_completion_capability/sequence_completion_capability_evaluation_{model}.csv'\n",
    "        )\n",
    "\n",
    "        rule_accs, completion_accs = [], []\n",
    "\n",
    "\n",
    "        for i, data in df.iterrows():\n",
    "            rule_accs.append(1 if data[\"generated_rule_matches\"] == True else 0)\n",
    "            completion_accs.append(1\n",
    "                    if data[\"generated_completion_matches\"] == True\n",
    "                    else 0)\n",
    "\n",
    "        result = {\n",
    "            \"model\": model,\n",
    "            \"run\": run,\n",
    "            \"rule_matches_sequence\": round(np.mean(rule_accs) * 100, 2),\n",
    "            \"completion_is_correct\": round(np.mean(completion_accs) * 100, 2),\n",
    "            \"len_completed\": len(df)\n",
    "        }\n",
    "        print(result)\n",
    "        capability_results.append(result)\n",
    "\n",
    "capability_df = pd.DataFrame(capability_results)\n",
    "capability_df.to_csv('./q0_capability_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb68665",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_corr_df = consistency_df[consistency_df.answer_validity == 'valid'].groupby('model').mean().merge(\n",
    "    capability_df.groupby('model').mean(), on=['model']\n",
    ")\n",
    "corr_df = to_corr_df[[\n",
    "    'rule_matches_sequence', 'completion_is_correct',\n",
    "    'ground_truth_consistent', 'ground_truth_consistent_num',\n",
    "       'self_rule_following_consistency',\n",
    "       'self_comparison_consistency',\n",
    "        'self_consistency_precision',\n",
    "       'self_consistency_recall', 'self_consistency_f1',\n",
    "    'rule_matches_sequence', 'completion_is_correct'\n",
    "]].corr()\n",
    "corr_df.to_csv('./q0_capability_consistency_corr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644287b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d69c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad3e5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b842be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.join('../..'))\n",
    "from src.pipelines import sequence_completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae8573b",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = sequence_completions.find_ambiguous_integer_sequences(num_steps_to_check=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b772367",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = sequence_completions.find_ambiguous_integer_sequences(num_steps_to_check=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c86d734",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = sequence_completions.find_ambiguous_integer_sequences(num_steps_to_check=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d643228",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([v for l in c.values() for v in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42329c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute capability v consistency\n",
    "import random\n",
    "consistency_scores = []\n",
    "points = []\n",
    "ambigs = a | b | c\n",
    "for seq, fns in ambigs.items():\n",
    "    for _ in range(len(fns)):\n",
    "        for _ in range(100):\n",
    "            f1 = random.choice(fns)\n",
    "            f2 = random.choice(fns)\n",
    "            consistency_scores.append(1 if f1 == f2 else 0)\n",
    "    x = sum(consistency_scores) / len(consistency_scores)\n",
    "    y = len(consistency_scores) /  (len([v for l in ambigs.values() for v in l]) * 100)\n",
    "    points.append(\n",
    "        [x * 100 , y * 100]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0ba347",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(consistency_scores) / len(consistency_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cea40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3d3b8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb00ff15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = to_corr_df[['ground_truth_consistent', 'rule_matches_sequence', 'self_comparison_consistency']].rename(\n",
    "    columns={'rule_matches_sequence': 'accuracy'}\n",
    ")\n",
    "df_1['style'] = 'explanation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c91158",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = to_corr_df[['ground_truth_consistent', 'completion_is_correct', 'self_comparison_consistency']].rename(\n",
    "    columns={'completion_is_correct': 'accuracy'}\n",
    ")\n",
    "df_2['style'] = 'completion'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f65bb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.concat([df_1, df_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e17fdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2,  sharex=True, figsize=(10,5))\n",
    "ax = sns.scatterplot(df_new,\n",
    "    y='ground_truth_consistent', x='accuracy', hue='model',\n",
    "    ax=axes[0], legend = False\n",
    ")\n",
    "sns.lineplot(df_new,\n",
    "    y='ground_truth_consistent', x='accuracy', style='style',\n",
    "             ax=axes[0], legend = False\n",
    ")\n",
    "ax.set(ylabel='Consistency', xlabel='Accuracy')\n",
    "ax.set(title='Ground truth consistency v Accuracy (r=0.96)')\n",
    "\n",
    "ax = sns.scatterplot(df_new,\n",
    "    y='self_comparison_consistency', x='accuracy', hue='model', ax=axes[1])\n",
    "sns.lineplot(df_new,\n",
    "    y='self_comparison_consistency', x='accuracy', style='style',\n",
    "             ax=axes[1]\n",
    ")\n",
    "ax.set(ylabel='Consistency (Self comparison)', xlabel='Accuracy')\n",
    "ax.set(title='Consistency (Self comparison) v Accuracy (r=-0.685)')\n",
    "\n",
    "ax.legend(loc=(1.1, 0.5))\n",
    "#plt.plot([point[1] for point in points[19:-21]], [point[0] for point\n",
    "\n",
    "#plt.plot([point[1] for point in points[19:-21]], [point[0] for point in points[19:-21]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93428f8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa76584",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d504d9c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfd7a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(to_corr_df,\n",
    "    y='self_comparison_consistency', x='completion_is_correct', hue='model')\n",
    "ax.set(ylabel='Consistency (Self comparison)', xlabel='Sequence completion accuracy')\n",
    "ax.set(title='Consistency (Self comparison) v Sequence completion accuracy (r=-0.49)')\n",
    "#plt.plot([point[1] for point in points[53:-10]], [point[0] for point in points[53:-10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2621726",
   "metadata": {},
   "outputs": [],
   "source": [
    "((-0.88 + -0.49) / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b625bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cc6c37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
