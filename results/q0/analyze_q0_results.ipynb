{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b0a9b3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mcompute_dependence_with_base_changes=False,sequence_completion_equality.model=davinci,string_transformation_completion_equality=False\u001b[m\u001b[m\r\n",
      "\u001b[1m\u001b[36mcompute_dependence_with_base_changes=False,sequence_completion_equality.model=gpt-3.5-turbo,string_transformation_completion_equality=False\u001b[m\u001b[m\r\n",
      "\u001b[1m\u001b[36mcompute_dependence_with_base_changes=False,sequence_completion_equality.model=gpt-4-0314,string_transformation_completion_equality=False\u001b[m\u001b[m\r\n",
      "\u001b[1m\u001b[36mcompute_dependence_with_base_changes=False,sequence_completion_equality.model=text-davinci-003,string_transformation_completion_equality=False\u001b[m\u001b[m\r\n",
      "multirun.yaml\r\n"
     ]
    }
   ],
   "source": [
    "!ls \"gpt_results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "491b280b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "514d264c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            For davinci including valid answers\n",
      "            Evaluated 173 ambiguous sequences of 225 total.\n",
      "            Resulting in:\n",
      "            - 26.090000000000003% ground-truth-consistent (using 23)\n",
      "            - 56.52% self-rule-following-consistency (using 23)\n",
      "            - 96.31% self-comparison-consistency (using 217)\n",
      "            - 26.090000000000003% self-comparison-consistency and ground-truth-consistent. (using 23)\n",
      "            \n",
      "\n",
      "            For gpt-3.5-turbo including valid answers\n",
      "            Evaluated 173 ambiguous sequences of 225 total.\n",
      "            Resulting in:\n",
      "            - 94.67999999999999% ground-truth-consistent (using 188)\n",
      "            - 95.74000000000001% self-rule-following-consistency (using 188)\n",
      "            - 94.42% self-comparison-consistency (using 215)\n",
      "            - 89.89% self-comparison-consistency and ground-truth-consistent. (using 188)\n",
      "            \n",
      "\n",
      "            For gpt-4-0314 including valid answers\n",
      "            Evaluated 173 ambiguous sequences of 225 total.\n",
      "            Resulting in:\n",
      "            - 94.64% ground-truth-consistent (using 168)\n",
      "            - 97.02% self-rule-following-consistency (using 168)\n",
      "            - 77.17% self-comparison-consistency (using 184)\n",
      "            - 73.81% self-comparison-consistency and ground-truth-consistent. (using 168)\n",
      "            \n",
      "\n",
      "            For text-davinci-003 including valid answers\n",
      "            Evaluated 173 ambiguous sequences of 225 total.\n",
      "            Resulting in:\n",
      "            - 88.44% ground-truth-consistent (using 173)\n",
      "            - 93.64% self-rule-following-consistency (using 173)\n",
      "            - 84.89% self-comparison-consistency (using 225)\n",
      "            - 83.82% self-comparison-consistency and ground-truth-consistent. (using 173)\n",
      "            \n",
      "\n",
      "            For davinci including all answers\n",
      "            Evaluated 173 ambiguous sequences of 225 total.\n",
      "            Resulting in:\n",
      "            - 2.76% ground-truth-consistent (using 217)\n",
      "            - 5.99% self-rule-following-consistency (using 217)\n",
      "            - 96.31% self-comparison-consistency (using 217)\n",
      "            - 88.48% self-comparison-consistency and ground-truth-consistent. (using 217)\n",
      "            \n",
      "\n",
      "            For gpt-3.5-turbo including all answers\n",
      "            Evaluated 173 ambiguous sequences of 225 total.\n",
      "            Resulting in:\n",
      "            - 82.78999999999999% ground-truth-consistent (using 215)\n",
      "            - 83.72% self-rule-following-consistency (using 215)\n",
      "            - 94.42% self-comparison-consistency (using 215)\n",
      "            - 90.7% self-comparison-consistency and ground-truth-consistent. (using 215)\n",
      "            \n",
      "\n",
      "            For gpt-4-0314 including all answers\n",
      "            Evaluated 173 ambiguous sequences of 225 total.\n",
      "            Resulting in:\n",
      "            - 86.41% ground-truth-consistent (using 184)\n",
      "            - 88.59% self-rule-following-consistency (using 184)\n",
      "            - 77.17% self-comparison-consistency (using 184)\n",
      "            - 72.83% self-comparison-consistency and ground-truth-consistent. (using 184)\n",
      "            \n",
      "\n",
      "            For text-davinci-003 including all answers\n",
      "            Evaluated 173 ambiguous sequences of 225 total.\n",
      "            Resulting in:\n",
      "            - 68.0% ground-truth-consistent (using 225)\n",
      "            - 72.0% self-rule-following-consistency (using 225)\n",
      "            - 84.89% self-comparison-consistency (using 225)\n",
      "            - 79.11% self-comparison-consistency and ground-truth-consistent. (using 225)\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "models = [\n",
    "    \"davinci\", \"gpt-3.5-turbo\", \"gpt-4-0314\", \"text-davinci-003\"\n",
    "]\n",
    "results = []\n",
    "for answer_validity in ['valid', 'all']:\n",
    "    for model in models:\n",
    "        df = pd.read_csv(\n",
    "                f'./gpt_results/compute_dependence_with_base_changes=False,sequence_completion_equality.model={model},string_transformation_completion_equality=False/evaluate_sequence_completion_equality/sequence_completion_equality_evaluation_{model}.csv'\n",
    "        )\n",
    "        match_accs, model_match_accs, model_consistency_accs, consistent_and_matched = (\n",
    "            [],\n",
    "            [],\n",
    "            [],\n",
    "            [],\n",
    "        )\n",
    "        for i, data in df.iterrows():\n",
    "            if answer_validity == 'valid' and  data[\"generated_completion_matches\"] is not True and data[\"generated_completion_matches\"] is not False:\n",
    "                continue\n",
    "            match_accs.append(1 if data[\"generated_completion_matches\"] == True else 0)\n",
    "\n",
    "        for i, data in df.iterrows():\n",
    "            if answer_validity == 'valid' and data[\"model_completion_matches\"] is not True and data[\"model_completion_matches\"] is not False:\n",
    "                continue\n",
    "            model_match_accs.append(1 if data[\"model_completion_matches\"] == True else 0)\n",
    "            \n",
    "        for i, data in df.iterrows():\n",
    "            if answer_validity == 'valid' and data[\"model_self_consistency_evaluation\"].strip() != \"Y\" and data[\"model_self_consistency_evaluation\"].strip() != \"N\":\n",
    "                continue\n",
    "            model_consistency_accs.append(\n",
    "                1 if data[\"model_self_consistency_evaluation\"].strip() == \"Y\" else 0\n",
    "            )\n",
    "            \n",
    "        for i, data in df.iterrows():\n",
    "            if answer_validity == 'valid' and data[\"model_self_consistency_evaluation\"].strip() != \"Y\" and data[\"model_self_consistency_evaluation\"].strip() != \"N\":\n",
    "                continue\n",
    "            if answer_validity == 'valid' and  data[\"generated_completion_matches\"] is not True and data[\"generated_completion_matches\"] is not False:\n",
    "                continue\n",
    "            consistent_and_matched.append(\n",
    "                1\n",
    "                if data[\"model_self_consistency_evaluation\"].strip() == \"Y\"\n",
    "                and data[\"generated_completion_matches\"]\n",
    "                else 0\n",
    "            )\n",
    "\n",
    "\n",
    "        ground_truth_consistent = round(np.mean(match_accs), 4) * 100\n",
    "        self_rule_following_consistency = round(np.mean(model_match_accs), 4) * 100\n",
    "        self_comparison_consistency = round(np.mean(model_consistency_accs), 4) * 100\n",
    "        consistent_and_matched_accuracy = round(np.mean(consistent_and_matched), 4) * 100\n",
    "        total_sequences = 225\n",
    "        \n",
    "        results.append({\n",
    "            \"model\": model,\n",
    "            \"answer_validity\": answer_validity,\n",
    "            \"ground_truth_consistent\": ground_truth_consistent,\n",
    "            \"ground_truth_consistent_num\": len(match_accs),\n",
    "            \"self_rule_following_consistency\":  self_rule_following_consistency, \n",
    "            \"self_rule_following_consistency_len\": len(model_match_accs),\n",
    "            \"self_comparison_consistency\": self_comparison_consistency,\n",
    "            \"self_comparison_consistency_len\": len(model_consistency_accs),\n",
    "            \"consistent_and_matched_accuracy\": consistent_and_matched_accuracy,\n",
    "            \"consistent_and_matched_accuracy_len\": len(consistent_and_matched)\n",
    "        })\n",
    "        print(\n",
    "            f\"\"\"\n",
    "            For {model} including {answer_validity} answers\n",
    "            Evaluated {count} ambiguous sequences of {total_sequences} total.\n",
    "            Resulting in:\n",
    "            - {ground_truth_consistent}% ground-truth-consistent (using {len(match_accs)})\n",
    "            - {self_rule_following_consistency}% self-rule-following-consistency (using {len(model_match_accs)})\n",
    "            - {self_comparison_consistency}% self-comparison-consistency (using {len(model_consistency_accs)})\n",
    "            - {consistent_and_matched_accuracy}% self-comparison-consistency and ground-truth-consistent. (using {len(consistent_and_matched)})\n",
    "            \"\"\"\n",
    "    )\n",
    "pd.DataFrame(results).to_csv('./q0_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "97c37b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "consistent_functions = []\n",
    "for model in models:\n",
    "    df = pd.read_csv(\n",
    "            f'./gpt_results/compute_dependence_with_base_changes=False,sequence_completion_equality.model={model},string_transformation_completion_equality=False/evaluate_sequence_completion_equality/sequence_completion_equality_evaluation_{model}.csv'\n",
    "    )\n",
    "    for i, data in df.iterrows():\n",
    "        if data[\"generated_completion_matches\"] is True:\n",
    "            consistent_functions.append({\n",
    "                \"fn\": data['original_function'],\n",
    "                \"model\": model\n",
    "            })\n",
    "            \n",
    "pd.DataFrame(\n",
    "    consistent_functions\n",
    ").to_csv('./consistent_functions_by_model.csv')\n",
    "            \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
