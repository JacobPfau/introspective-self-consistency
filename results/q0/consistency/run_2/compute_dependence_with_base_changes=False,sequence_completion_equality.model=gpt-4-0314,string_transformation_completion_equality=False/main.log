[2023-06-01 21:26:56,107][src.utils][INFO] - Git sha: a78aae517535a9760211e71ffc591118b750a75c
[2023-06-01 21:26:56,126][src.utils][INFO] - Changed files: ['results/q0/analyze_q0_results.ipynb', 'results/q0/q0_results.csv', 'src/evals/sequence_completion.py']
[2023-06-01 21:26:56,142][src.utils][INFO] - Git diff:
diff --git a/results/q0/analyze_q0_results.ipynb b/results/q0/analyze_q0_results.ipynb
index 36ce41e..7f86d30 100644
--- a/results/q0/analyze_q0_results.ipynb
+++ b/results/q0/analyze_q0_results.ipynb
@@ -2,7 +2,7 @@
  "cells": [
   {
    "cell_type": "code",
-   "execution_count": 44,
+   "execution_count": 1,
    "id": "b0a9b3a5",
    "metadata": {},
    "outputs": [
@@ -13,6 +13,7 @@
       "\u001b[1m\u001b[36mcompute_dependence_with_base_changes=False,sequence_completion_equality.model=davinci,string_transformation_completion_equality=False\u001b[m\u001b[m\r\n",
       "\u001b[1m\u001b[36mcompute_dependence_with_base_changes=False,sequence_completion_equality.model=gpt-3.5-turbo,string_transformation_completion_equality=False\u001b[m\u001b[m\r\n",
       "\u001b[1m\u001b[36mcompute_dependence_with_base_changes=False,sequence_completion_equality.model=gpt-4-0314,string_transformation_completion_equality=False\u001b[m\u001b[m\r\n",
+      "\u001b[1m\u001b[36mcompute_dependence_with_base_changes=False,sequence_completion_equality.model=gpt-4-0314-run-2,string_transformation_completion_equality=False\u001b[m\u001b[m\r\n",
       "\u001b[1m\u001b[36mcompute_dependence_with_base_changes=False,sequence_completion_equality.model=text-davinci-003,string_transformation_completion_equality=False\u001b[m\u001b[m\r\n",
       "multirun.yaml\r\n"
      ]
@@ -24,15 +25,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 45,
-   "id": "491b280b",
-   "metadata": {},
-   "outputs": [],
-   "source": []
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 62,
+   "execution_count": 5,
    "id": "514d264c",
    "metadata": {},
    "outputs": [
@@ -42,7 +35,7 @@
      "text": [
       "\n",
       "            For davinci including valid answers\n",
-      "            Evaluated 173 ambiguous sequences of 225 total.\n",
+      "            Evaluated 217 ambiguous sequences of 225 total.\n",
       "            Resulting in:\n",
       "            - 26.090000000000003% ground-truth-consistent (using 23)\n",
       "            - 56.52% self-rule-following-consistency (using 23)\n",
@@ -51,7 +44,7 @@
       "            \n",
       "\n",
       "            For gpt-3.5-turbo including valid answers\n",
-      "            Evaluated 173 ambiguous sequences of 225 total.\n",
+      "            Evaluated 215 ambiguous sequences of 225 total.\n",
       "            Resulting in:\n",
       "            - 94.67999999999999% ground-truth-consistent (using 188)\n",
       "            - 95.74000000000001% self-rule-following-consistency (using 188)\n",
@@ -60,7 +53,7 @@
       "            \n",
       "\n",
       "            For gpt-4-0314 including valid answers\n",
-      "            Evaluated 173 ambiguous sequences of 225 total.\n",
+      "            Evaluated 184 ambiguous sequences of 225 total.\n",
       "            Resulting in:\n",
       "            - 94.64% ground-truth-consistent (using 168)\n",
       "            - 97.02% self-rule-following-consistency (using 168)\n",
@@ -68,8 +61,17 @@
       "            - 73.81% self-comparison-consistency and ground-truth-consistent. (using 168)\n",
       "            \n",
       "\n",
+      "            For gpt-4-0314-run-2 including valid answers\n",
+      "            Evaluated 107 ambiguous sequences of 225 total.\n",
+      "            Resulting in:\n",
+      "            - 98.08% ground-truth-consistent (using 104)\n",
+      "            - 98.08% self-rule-following-consistency (using 104)\n",
+      "            - 76.64% self-comparison-consistency (using 107)\n",
+      "            - 75.0% self-comparison-consistency and ground-truth-consistent. (using 104)\n",
+      "            \n",
+      "\n",
       "            For text-davinci-003 including valid answers\n",
-      "            Evaluated 173 ambiguous sequences of 225 total.\n",
+      "            Evaluated 225 ambiguous sequences of 225 total.\n",
       "            Resulting in:\n",
       "            - 88.44% ground-truth-consistent (using 173)\n",
       "            - 93.64% self-rule-following-consistency (using 173)\n",
@@ -78,7 +80,7 @@
       "            \n",
       "\n",
       "            For davinci including all answers\n",
-      "            Evaluated 173 ambiguous sequences of 225 total.\n",
+      "            Evaluated 217 ambiguous sequences of 225 total.\n",
       "            Resulting in:\n",
       "            - 2.76% ground-truth-consistent (using 217)\n",
       "            - 5.99% self-rule-following-consistency (using 217)\n",
@@ -87,7 +89,7 @@
       "            \n",
       "\n",
       "            For gpt-3.5-turbo including all answers\n",
-      "            Evaluated 173 ambiguous sequences of 225 total.\n",
+      "            Evaluated 215 ambiguous sequences of 225 total.\n",
       "            Resulting in:\n",
       "            - 82.78999999999999% ground-truth-consistent (using 215)\n",
       "            - 83.72% self-rule-following-consistency (using 215)\n",
@@ -96,7 +98,7 @@
       "            \n",
       "\n",
       "            For gpt-4-0314 including all answers\n",
-      "            Evaluated 173 ambiguous sequences of 225 total.\n",
+      "            Evaluated 184 ambiguous sequences of 225 total.\n",
       "            Resulting in:\n",
       "            - 86.41% ground-truth-consistent (using 184)\n",
       "            - 88.59% self-rule-following-consistency (using 184)\n",
@@ -104,8 +106,17 @@
       "            - 72.83% self-comparison-consistency and ground-truth-consistent. (using 184)\n",
       "            \n",
       "\n",
+      "            For gpt-4-0314-run-2 including all answers\n",
+      "            Evaluated 107 ambiguous sequences of 225 total.\n",
+      "            Resulting in:\n",
+      "            - 95.33% ground-truth-consistent (using 107)\n",
+      "            - 95.33% self-rule-following-consistency (using 107)\n",
+      "            - 76.64% self-comparison-consistency (using 107)\n",
+      "            - 74.77000000000001% self-comparison-consistency and ground-truth-consistent. (using 107)\n",
+      "            \n",
+      "\n",
       "            For text-davinci-003 including all answers\n",
-      "            Evaluated 173 ambiguous sequences of 225 total.\n",
+      "            Evaluated 225 ambiguous sequences of 225 total.\n",
       "            Resulting in:\n",
       "            - 68.0% ground-truth-consistent (using 225)\n",
       "            - 72.0% self-rule-following-consistency (using 225)\n",
@@ -117,9 +128,9 @@
    ],
    "source": [
     "import numpy as np\n",
-    "\n",
+    "import pandas as pd\n",
     "models = [\n",
-    "    \"davinci\", \"gpt-3.5-turbo\", \"gpt-4-0314\", \"text-davinci-003\"\n",
+    "    \"davinci\", \"gpt-3.5-turbo\", \"gpt-4-0314\", \"gpt-4-0314-run-2\", \"text-davinci-003\"\n",
     "]\n",
     "results = []\n",
     "for answer_validity in ['valid', 'all']:\n",
@@ -184,7 +195,7 @@
     "        print(\n",
     "            f\"\"\"\n",
     "            For {model} including {answer_validity} answers\n",
-    "            Evaluated {count} ambiguous sequences of {total_sequences} total.\n",
+    "            Evaluated {len(df)} ambiguous sequences of {total_sequences} total.\n",
     "            Resulting in:\n",
     "            - {ground_truth_consistent}% ground-truth-consistent (using {len(match_accs)})\n",
     "            - {self_rule_following_consistency}% self-rule-following-consistency (using {len(model_match_accs)})\n",
diff --git a/results/q0/q0_results.csv b/results/q0/q0_results.csv
index f6dfcfd..eb87bb4 100644
--- a/results/q0/q0_results.csv
+++ b/results/q0/q0_results.csv
@@ -2,8 +2,10 @@
 0,davinci,valid,26.090000000000003,23,56.52,23,96.31,217,26.090000000000003,23
 1,gpt-3.5-turbo,valid,94.67999999999999,188,95.74000000000001,188,94.42,215,89.89,188
 2,gpt-4-0314,valid,94.64,168,97.02,168,77.17,184,73.81,168
-3,text-davinci-003,valid,88.44,173,93.64,173,84.89,225,83.82,173
-4,davinci,all,2.76,217,5.99,217,96.31,217,88.48,217
-5,gpt-3.5-turbo,all,82.78999999999999,215,83.72,215,94.42,215,90.7,215
-6,gpt-4-0314,all,86.41,184,88.59,184,77.17,184,72.83,184
-7,text-davinci-003,all,68.0,225,72.0,225,84.89,225,79.11,225
+3,gpt-4-0314-run-2,valid,98.08,104,98.08,104,76.64,107,75.0,104
+4,text-davinci-003,valid,88.44,173,93.64,173,84.89,225,83.82,173
+5,davinci,all,2.76,217,5.99,217,96.31,217,88.48,217
+6,gpt-3.5-turbo,all,82.78999999999999,215,83.72,215,94.42,215,90.7,215
+7,gpt-4-0314,all,86.41,184,88.59,184,77.17,184,72.83,184
+8,gpt-4-0314-run-2,all,95.33,107,95.33,107,76.64,107,74.77000000000001,107
+9,text-davinci-003,all,68.0,225,72.0,225,84.89,225,79.11,225
diff --git a/src/evals/sequence_completion.py b/src/evals/sequence_completion.py
index c887125..a44cbe6 100644
--- a/src/evals/sequence_completion.py
+++ b/src/evals/sequence_completion.py
@@ -203,11 +203,12 @@ def evaluate_sequence_completion_equality(
         f"sequence_completion_equality_evaluation_{model}.csv", index=False
     )

-    match_accs, model_match_accs, model_consistency_accs, consistent_and_matched = (
+    match_accs, model_match_accs, model_consistency_accs, consistent_and_matched_positive, consistent_and_matched_negative = (
         [],
         [],
         [],
         [],
+        []
     )
     for data in completion_data:
         match_accs.append(1 if data["generated_completion_matches"] else 0)
@@ -215,17 +216,24 @@ def evaluate_sequence_completion_equality(
         model_consistency_accs.append(
             1 if data["model_self_consistency_evaluation"].strip() == "Y" else 0
         )
-        consistent_and_matched.append(
+        consistent_and_matched_positive.append(
             1
             if data["model_self_consistency_evaluation"].strip() == "Y"
             and data["generated_completion_matches"]
             else 0
         )
+        consistent_and_matched_negative.append(
+            1
+            if data["model_self_consistency_evaluation"].strip() == "N"
+            and not data["generated_completion_matches"]
+            else 0
+        )

     ground_truth_consistent = round(np.mean(match_accs), 2) * 100
     self_rule_following_consistency = round(np.mean(model_match_accs), 2) * 100
     self_comparison_consistency = round(np.mean(model_consistency_accs), 2) * 100
-    consistent_and_matched_accuracy = round(np.mean(consistent_and_matched), 2) * 100
+    consistent_and_matched_positive_accuracy = round(np.mean(consistent_and_matched_positive), 2) * 100
+    consistent_and_matched_negative_accuracy = round(np.mean(consistent_and_matched_negative), 2) * 100
     logger.info(
         f"""
         Evaluated {len(completion_data)} ambiguous sequences of {total_sequences} total.
@@ -233,6 +241,7 @@ def evaluate_sequence_completion_equality(
         - {ground_truth_consistent}% ground-truth-consistent
         - {self_rule_following_consistency}% self-rule-following-consistency
         - {self_comparison_consistency}% self-comparison-consistency
-        - {consistent_and_matched_accuracy}% self-comparison-consistency and ground-truth-consistent.
+        - {consistent_and_matched_positive_accuracy}% self-comparison-consistency and ground-truth-consistent (positive).
+        - {consistent_and_matched_negative_accuracy}% self-comparison-consistency and ground-truth-consistent (negative).
         """
     )
[2023-06-01 21:26:56,145][src.utils][INFO] - Changed directory to /Users/domenicrosati/src/introspective-self-consistency/results/2023-06-01-17-03-02/compute_dependence_with_base_changes=False,sequence_completion_equality.model=gpt-4-0314,string_transformation_completion_equality=False/evaluate_sequence_completion_equality
[2023-06-01 21:26:56,145][src.evals.sequence_completion][INFO] - Evaluating sequence completion equality...
[2023-06-01 21:29:20,828][src.evals.sequence_completion][ERROR] - unterminated string literal (detected at line 1) (<string>, line 1)
Traceback (most recent call last):
  File "/Users/domenicrosati/src/introspective-self-consistency/src/evals/sequence_completion.py", line 187, in evaluate_sequence_completion_equality
    sequence_completion_equality(
  File "/Users/domenicrosati/src/introspective-self-consistency/src/evals/sequence_completion.py", line 139, in sequence_completion_equality
    completion = eval(explanation)(i)
  File "<string>", line 1
    This sequence does not follow a simple arithmetic or geometric pattern. However, you can generate it using a list or a custom function. Here's one way to do it:
                                                                                                                                                ^
SyntaxError: unterminated string literal (detected at line 1)
[2023-06-01 21:29:20,828][src.evals.sequence_completion][WARNING] - unterminated string literal (detected at line 1) (<string>, line 1)
[2023-06-01 21:29:37,617][src.evals.sequence_completion][ERROR] - unterminated string literal (detected at line 1) (<string>, line 1)
Traceback (most recent call last):
  File "/Users/domenicrosati/src/introspective-self-consistency/src/evals/sequence_completion.py", line 187, in evaluate_sequence_completion_equality
    sequence_completion_equality(
  File "/Users/domenicrosati/src/introspective-self-consistency/src/evals/sequence_completion.py", line 139, in sequence_completion_equality
    completion = eval(explanation)(i)
  File "<string>", line 1
    Here's a code that generates the sequence 1, 2, 3, 5:
        ^
SyntaxError: unterminated string literal (detected at line 1)
[2023-06-01 21:29:37,618][src.evals.sequence_completion][WARNING] - unterminated string literal (detected at line 1) (<string>, line 1)
[2023-06-01 21:29:54,225][src.evals.sequence_completion][ERROR] - invalid syntax (<string>, line 1)
Traceback (most recent call last):
  File "/Users/domenicrosati/src/introspective-self-consistency/src/evals/sequence_completion.py", line 187, in evaluate_sequence_completion_equality
    sequence_completion_equality(
  File "/Users/domenicrosati/src/introspective-self-consistency/src/evals/sequence_completion.py", line 139, in sequence_completion_equality
    completion = eval(explanation)(i)
  File "<string>", line 1
    This sequence does not follow a simple arithmetic or geometric pattern. However, if you meant the Fibonacci sequence, which starts with 1, 1, 2, 3, 5, ... then the code would be:
         ^^^^^^^^
SyntaxError: invalid syntax
[2023-06-01 21:29:54,226][src.evals.sequence_completion][WARNING] - invalid syntax (<string>, line 1)
[2023-06-01 21:30:09,143][src.evals.sequence_completion][ERROR] - unterminated string literal (detected at line 1) (<string>, line 1)
Traceback (most recent call last):
  File "/Users/domenicrosati/src/introspective-self-consistency/src/evals/sequence_completion.py", line 187, in evaluate_sequence_completion_equality
    sequence_completion_equality(
  File "/Users/domenicrosati/src/introspective-self-consistency/src/evals/sequence_completion.py", line 139, in sequence_completion_equality
    completion = eval(explanation)(i)
  File "<string>", line 1
    Here's a code that generates the sequence 1, 2, 3, 5:
        ^
SyntaxError: unterminated string literal (detected at line 1)
[2023-06-01 21:30:09,143][src.evals.sequence_completion][WARNING] - unterminated string literal (detected at line 1) (<string>, line 1)
[2023-06-01 21:30:29,292][src.evals.sequence_completion][ERROR] - invalid syntax (<string>, line 1)
Traceback (most recent call last):
  File "/Users/domenicrosati/src/introspective-self-consistency/src/evals/sequence_completion.py", line 187, in evaluate_sequence_completion_equality
    sequence_completion_equality(
  File "/Users/domenicrosati/src/introspective-self-consistency/src/evals/sequence_completion.py", line 139, in sequence_completion_equality
    completion = eval(explanation)(i)
  File "<string>", line 1
    This sequence does not follow a simple arithmetic or geometric pattern. However, you can generate it using a custom function:
         ^^^^^^^^
SyntaxError: invalid syntax
[2023-06-01 21:30:29,293][src.evals.sequence_completion][WARNING] - invalid syntax (<string>, line 1)
[2023-06-01 21:30:56,361][src.evals.sequence_completion][ERROR] - unterminated string literal (detected at line 1) (<string>, line 1)
Traceback (most recent call last):
  File "/Users/domenicrosati/src/introspective-self-consistency/src/evals/sequence_completion.py", line 187, in evaluate_sequence_completion_equality
    sequence_completion_equality(
  File "/Users/domenicrosati/src/introspective-self-consistency/src/evals/sequence_completion.py", line 139, in sequence_completion_equality
    completion = eval(explanation)(i)
  File "<string>", line 1
    Here's a code that generates the sequence 3, 5, 6, 7:
        ^
SyntaxError: unterminated string literal (detected at line 1)
[2023-06-01 21:30:56,361][src.evals.sequence_completion][WARNING] - unterminated string literal (detected at line 1) (<string>, line 1)
[2023-06-01 21:31:06,167][src.evals.sequence_completion][ERROR] - unterminated string literal (detected at line 1) (<string>, line 1)
Traceback (most recent call last):
  File "/Users/domenicrosati/src/introspective-self-consistency/src/evals/sequence_completion.py", line 187, in evaluate_sequence_completion_equality
    sequence_completion_equality(
  File "/Users/domenicrosati/src/introspective-self-consistency/src/evals/sequence_completion.py", line 139, in sequence_completion_equality
    completion = eval(explanation)(i)
  File "<string>", line 1
    Here's a piecewise function that generates the given sequence:
        ^
SyntaxError: unterminated string literal (detected at line 1)
[2023-06-01 21:31:06,167][src.evals.sequence_completion][WARNING] - unterminated string literal (detected at line 1) (<string>, line 1)
[2023-06-01 21:31:32,269][src.evals.sequence_completion][ERROR] - invalid syntax (<string>, line 1)
Traceback (most recent call last):
  File "/Users/domenicrosati/src/introspective-self-consistency/src/evals/sequence_completion.py", line 187, in evaluate_sequence_completion_equality
    sequence_completion_equality(
  File "/Users/domenicrosati/src/introspective-self-consistency/src/evals/sequence_completion.py", line 139, in sequence_completion_equality
    completion = eval(explanation)(i)
  File "<string>", line 1
    This sequence does not follow a simple arithmetic or geometric pattern. However, you can generate it using a custom function:
         ^^^^^^^^
SyntaxError: invalid syntax
[2023-06-01 21:31:32,269][src.evals.sequence_completion][WARNING] - invalid syntax (<string>, line 1)
[2023-06-01 21:42:32,985][src.evals.sequence_completion][ERROR] - unterminated string literal (detected at line 1) (<string>, line 1)
Traceback (most recent call last):
  File "/Users/domenicrosati/src/introspective-self-consistency/src/evals/sequence_completion.py", line 187, in evaluate_sequence_completion_equality
    sequence_completion_equality(
  File "/Users/domenicrosati/src/introspective-self-consistency/src/evals/sequence_completion.py", line 139, in sequence_completion_equality
    completion = eval(explanation)(i)
  File "<string>", line 1
    Here's a possible code to generate the sequence 4, 5, 7, 8:
        ^
SyntaxError: unterminated string literal (detected at line 1)
[2023-06-01 21:42:32,985][src.evals.sequence_completion][WARNING] - unterminated string literal (detected at line 1) (<string>, line 1)
[2023-06-01 21:42:46,718][src.evals.sequence_completion][ERROR] - unterminated string literal (detected at line 1) (<string>, line 1)
Traceback (most recent call last):
  File "/Users/domenicrosati/src/introspective-self-consistency/src/evals/sequence_completion.py", line 187, in evaluate_sequence_completion_equality
    sequence_completion_equality(
  File "/Users/domenicrosati/src/introspective-self-consistency/src/evals/sequence_completion.py", line 139, in sequence_completion_equality
    completion = eval(explanation)(i)
  File "<string>", line 1
    Here's a possible code that generates the sequence 4, 5, 7, 8:
        ^
SyntaxError: unterminated string literal (detected at line 1)
[2023-06-01 21:42:46,718][src.evals.sequence_completion][WARNING] - unterminated string literal (detected at line 1) (<string>, line 1)
[2023-06-01 21:43:01,514][src.evals.sequence_completion][ERROR] - invalid syntax (<string>, line 1)
Traceback (most recent call last):
  File "/Users/domenicrosati/src/introspective-self-consistency/src/evals/sequence_completion.py", line 187, in evaluate_sequence_completion_equality
    sequence_completion_equality(
  File "/Users/domenicrosati/src/introspective-self-consistency/src/evals/sequence_completion.py", line 139, in sequence_completion_equality
    completion = eval(explanation)(i)
  File "<string>", line 1
    This sequence does not follow a simple arithmetic or geometric pattern. However, you can generate it using a custom function:
         ^^^^^^^^
SyntaxError: invalid syntax
[2023-06-01 21:43:01,514][src.evals.sequence_completion][WARNING] - invalid syntax (<string>, line 1)
[2023-06-01 21:43:32,713][src.evals.sequence_completion][ERROR] - unterminated string literal (detected at line 1) (<string>, line 1)
Traceback (most recent call last):
  File "/Users/domenicrosati/src/introspective-self-consistency/src/evals/sequence_completion.py", line 187, in evaluate_sequence_completion_equality
    sequence_completion_equality(
  File "/Users/domenicrosati/src/introspective-self-consistency/src/evals/sequence_completion.py", line 139, in sequence_completion_equality
    completion = eval(explanation)(i)
  File "<string>", line 1
    Here's a piecewise function that generates the sequence:
        ^
SyntaxError: unterminated string literal (detected at line 1)
[2023-06-01 21:43:32,713][src.evals.sequence_completion][WARNING] - unterminated string literal (detected at line 1) (<string>, line 1)
[2023-06-01 21:44:03,855][src.evals.sequence_completion][ERROR] - invalid syntax (<string>, line 1)
Traceback (most recent call last):
  File "/Users/domenicrosati/src/introspective-self-consistency/src/evals/sequence_completion.py", line 187, in evaluate_sequence_completion_equality
    sequence_completion_equality(
  File "/Users/domenicrosati/src/introspective-self-consistency/src/evals/sequence_completion.py", line 139, in sequence_completion_equality
    completion = eval(explanation)(i)
  File "<string>", line 1
    The given sequence is not an arithmetic or geometric sequence. However, you can generate the sequence using a custom function:
        ^^^^^
SyntaxError: invalid syntax
[2023-06-01 21:44:03,855][src.evals.sequence_completion][WARNING] - invalid syntax (<string>, line 1)
[2023-06-01 21:46:38,562][openai][INFO] - error_code=None error_message='That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6692dc036cd7544fc524f88ab9fa0fee in your message.)' error_param=None error_type=server_error message='OpenAI API error received' stream_error=False
[2023-06-01 21:46:38,562][src.evals.sequence_completion][ERROR] - That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6692dc036cd7544fc524f88ab9fa0fee in your message.)
Traceback (most recent call last):
  File "/Users/domenicrosati/src/introspective-self-consistency/src/evals/sequence_completion.py", line 187, in evaluate_sequence_completion_equality
    sequence_completion_equality(
  File "/Users/domenicrosati/src/introspective-self-consistency/src/evals/sequence_completion.py", line 101, in sequence_completion_equality
    completion_resp = generate_response_with_turns(
  File "/Users/domenicrosati/src/introspective-self-consistency/src/models/completions.py", line 21, in generate_response_with_turns
    return openai_model.generate_response_with_turns(
  File "/Users/domenicrosati/src/introspective-self-consistency/src/models/openai_model.py", line 151, in generate_response_with_turns
    return generate_chat_completion(
  File "/Users/domenicrosati/src/introspective-self-consistency/src/models/openai_model.py", line 108, in generate_chat_completion
    response = openai.ChatCompletion.create(
  File "/Users/domenicrosati/.asdf/installs/python/3.10.4/lib/python3.10/site-packages/openai/api_resources/chat_completion.py", line 25, in create
    return super().create(*args, **kwargs)
  File "/Users/domenicrosati/.asdf/installs/python/3.10.4/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py", line 153, in create
    response, _, api_key = requestor.request(
  File "/Users/domenicrosati/.asdf/installs/python/3.10.4/lib/python3.10/site-packages/openai/api_requestor.py", line 226, in request
    resp, got_stream = self._interpret_response(result, stream)
  File "/Users/domenicrosati/.asdf/installs/python/3.10.4/lib/python3.10/site-packages/openai/api_requestor.py", line 619, in _interpret_response
    self._interpret_response_line(
  File "/Users/domenicrosati/.asdf/installs/python/3.10.4/lib/python3.10/site-packages/openai/api_requestor.py", line 682, in _interpret_response_line
    raise self.handle_error_response(
openai.error.RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6692dc036cd7544fc524f88ab9fa0fee in your message.)
[2023-06-01 21:46:38,564][src.evals.sequence_completion][WARNING] - That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6692dc036cd7544fc524f88ab9fa0fee in your message.)
[2023-06-01 21:46:50,889][src.evals.sequence_completion][INFO] -
        Evaluated 211 ambiguous sequences of 225 total.
        Resulting in:
        - 87.0% ground-truth-consistent
        - 87.0% self-rule-following-consistency
        - 79.0% self-comparison-consistency
        - 69.0% self-comparison-consistency and ground-truth-consistent (positive).
        - 3.0% self-comparison-consistency and ground-truth-consistent (negative).
