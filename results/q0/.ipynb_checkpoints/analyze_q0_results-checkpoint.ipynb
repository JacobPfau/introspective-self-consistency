{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "514d264c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                For run_1 run davinci including valid answers\n",
      "                Evaluated 222 ambiguous sequences of 225 total.\n",
      "                Resulting in:\n",
      "                - 0.36363636363636365% ground-truth-consistent (using 33)\n",
      "                - 0.3333333333333333% self-rule-following-consistency (using 33)\n",
      "                - 0.9504504504504504% self-comparison-consistency (using 222)\n",
      "                - 1.0% self-comparison-consistency==Y and ground-truth-consistent. (using 12)\n",
      "                - 0.047619047619047616% self-comparison-consistency==N and not ground-truth-consistent. (using 21)\n",
      "                \n",
      "\n",
      "                For run_2 run davinci including valid answers\n",
      "                Evaluated 220 ambiguous sequences of 225 total.\n",
      "                Resulting in:\n",
      "                - 0.29411764705882354% ground-truth-consistent (using 34)\n",
      "                - 0.4117647058823529% self-rule-following-consistency (using 34)\n",
      "                - 0.9681818181818181% self-comparison-consistency (using 220)\n",
      "                - 0.9% self-comparison-consistency==Y and ground-truth-consistent. (using 10)\n",
      "                - 0.0% self-comparison-consistency==N and not ground-truth-consistent. (using 24)\n",
      "                \n",
      "\n",
      "                For run_3 run davinci including valid answers\n",
      "                Evaluated 221 ambiguous sequences of 225 total.\n",
      "                Resulting in:\n",
      "                - 0.4642857142857143% ground-truth-consistent (using 28)\n",
      "                - 0.35714285714285715% self-rule-following-consistency (using 28)\n",
      "                - 0.9728506787330317% self-comparison-consistency (using 221)\n",
      "                - 1.0% self-comparison-consistency==Y and ground-truth-consistent. (using 13)\n",
      "                - 0.0% self-comparison-consistency==N and not ground-truth-consistent. (using 15)\n",
      "                \n",
      "\n",
      "                For run_1 run gpt-3.5-turbo including valid answers\n",
      "                Evaluated 217 ambiguous sequences of 225 total.\n",
      "                Resulting in:\n",
      "                - 0.9424083769633508% ground-truth-consistent (using 191)\n",
      "                - 0.9581151832460733% self-rule-following-consistency (using 191)\n",
      "                - 0.9534883720930233% self-comparison-consistency (using 215)\n",
      "                - 0.9777777777777777% self-comparison-consistency==Y and ground-truth-consistent. (using 180)\n",
      "                - 0.1% self-comparison-consistency==N and not ground-truth-consistent. (using 10)\n",
      "                \n",
      "\n",
      "                For run_2 run gpt-3.5-turbo including valid answers\n",
      "                Evaluated 213 ambiguous sequences of 225 total.\n",
      "                Resulting in:\n",
      "                - 0.9516129032258065% ground-truth-consistent (using 186)\n",
      "                - 0.9731182795698925% self-rule-following-consistency (using 186)\n",
      "                - 0.9669811320754716% self-comparison-consistency (using 212)\n",
      "                - 0.9830508474576272% self-comparison-consistency==Y and ground-truth-consistent. (using 177)\n",
      "                - 0.0% self-comparison-consistency==N and not ground-truth-consistent. (using 8)\n",
      "                \n",
      "\n",
      "                For run_3 run gpt-3.5-turbo including valid answers\n",
      "                Evaluated 212 ambiguous sequences of 225 total.\n",
      "                Resulting in:\n",
      "                - 0.9447513812154696% ground-truth-consistent (using 181)\n",
      "                - 0.9723756906077348% self-rule-following-consistency (using 181)\n",
      "                - 0.9620853080568721% self-comparison-consistency (using 211)\n",
      "                - 0.9824561403508771% self-comparison-consistency==Y and ground-truth-consistent. (using 171)\n",
      "                - 0.0% self-comparison-consistency==N and not ground-truth-consistent. (using 10)\n",
      "                \n",
      "\n",
      "                For run_1 run gpt-4-0314 including valid answers\n",
      "                Evaluated 210 ambiguous sequences of 225 total.\n",
      "                Resulting in:\n",
      "                - 0.9787234042553191% ground-truth-consistent (using 188)\n",
      "                - 0.9787234042553191% self-rule-following-consistency (using 188)\n",
      "                - 0.8095238095238095% self-comparison-consistency (using 210)\n",
      "                - 0.8097826086956522% self-comparison-consistency==Y and ground-truth-consistent. (using 184)\n",
      "                - 0.0% self-comparison-consistency==N and not ground-truth-consistent. (using 4)\n",
      "                \n",
      "\n",
      "                For run_2 run gpt-4-0314 including valid answers\n",
      "                Evaluated 211 ambiguous sequences of 225 total.\n",
      "                Resulting in:\n",
      "                - 0.9786096256684492% ground-truth-consistent (using 187)\n",
      "                - 0.983957219251337% self-rule-following-consistency (using 187)\n",
      "                - 0.7867298578199052% self-comparison-consistency (using 211)\n",
      "                - 0.7923497267759563% self-comparison-consistency==Y and ground-truth-consistent. (using 183)\n",
      "                - 0.25% self-comparison-consistency==N and not ground-truth-consistent. (using 4)\n",
      "                \n",
      "\n",
      "                For run_3 run gpt-4-0314 including valid answers\n",
      "                Evaluated 210 ambiguous sequences of 225 total.\n",
      "                Resulting in:\n",
      "                - 0.9680851063829787% ground-truth-consistent (using 188)\n",
      "                - 0.9680851063829787% self-rule-following-consistency (using 188)\n",
      "                - 0.8523809523809524% self-comparison-consistency (using 210)\n",
      "                - 0.8626373626373627% self-comparison-consistency==Y and ground-truth-consistent. (using 182)\n",
      "                - 0.16666666666666666% self-comparison-consistency==N and not ground-truth-consistent. (using 6)\n",
      "                \n",
      "\n",
      "                For run_1 run text-davinci-003 including valid answers\n",
      "                Evaluated 222 ambiguous sequences of 225 total.\n",
      "                Resulting in:\n",
      "                - 0.8895348837209303% ground-truth-consistent (using 172)\n",
      "                - 0.9127906976744186% self-rule-following-consistency (using 172)\n",
      "                - 0.8783783783783784% self-comparison-consistency (using 222)\n",
      "                - 0.9607843137254902% self-comparison-consistency==Y and ground-truth-consistent. (using 153)\n",
      "                - 0.2631578947368421% self-comparison-consistency==N and not ground-truth-consistent. (using 19)\n",
      "                \n",
      "\n",
      "                For run_2 run text-davinci-003 including valid answers\n",
      "                Evaluated 222 ambiguous sequences of 225 total.\n",
      "                Resulting in:\n",
      "                - 0.9017341040462428% ground-truth-consistent (using 173)\n",
      "                - 0.8959537572254336% self-rule-following-consistency (using 173)\n",
      "                - 0.8648648648648649% self-comparison-consistency (using 222)\n",
      "                - 0.9423076923076923% self-comparison-consistency==Y and ground-truth-consistent. (using 156)\n",
      "                - 0.23529411764705882% self-comparison-consistency==N and not ground-truth-consistent. (using 17)\n",
      "                \n",
      "\n",
      "                For run_3 run text-davinci-003 including valid answers\n",
      "                Evaluated 225 ambiguous sequences of 225 total.\n",
      "                Resulting in:\n",
      "                - 0.896551724137931% ground-truth-consistent (using 174)\n",
      "                - 0.8908045977011494% self-rule-following-consistency (using 174)\n",
      "                - 0.8755555555555555% self-comparison-consistency (using 225)\n",
      "                - 0.9230769230769231% self-comparison-consistency==Y and ground-truth-consistent. (using 156)\n",
      "                - 0.16666666666666666% self-comparison-consistency==N and not ground-truth-consistent. (using 18)\n",
      "                \n",
      "\n",
      "                For run_1 run davinci including all answers\n",
      "                Evaluated 222 ambiguous sequences of 225 total.\n",
      "                Resulting in:\n",
      "                - 0.05405405405405406% ground-truth-consistent (using 222)\n",
      "                - 0.04954954954954955% self-rule-following-consistency (using 222)\n",
      "                - 0.9504504504504504% self-comparison-consistency (using 222)\n",
      "                - 0.9502487562189055% self-comparison-consistency==Y and ground-truth-consistent. (using 201)\n",
      "                - 0.047619047619047616% self-comparison-consistency==N and not ground-truth-consistent. (using 21)\n",
      "                \n",
      "\n",
      "                For run_2 run davinci including all answers\n",
      "                Evaluated 220 ambiguous sequences of 225 total.\n",
      "                Resulting in:\n",
      "                - 0.045454545454545456% ground-truth-consistent (using 220)\n",
      "                - 0.06363636363636363% self-rule-following-consistency (using 220)\n",
      "                - 0.9681818181818181% self-comparison-consistency (using 220)\n",
      "                - 0.9642857142857143% self-comparison-consistency==Y and ground-truth-consistent. (using 196)\n",
      "                - 0.0% self-comparison-consistency==N and not ground-truth-consistent. (using 24)\n",
      "                \n",
      "\n",
      "                For run_3 run davinci including all answers\n",
      "                Evaluated 221 ambiguous sequences of 225 total.\n",
      "                Resulting in:\n",
      "                - 0.058823529411764705% ground-truth-consistent (using 221)\n",
      "                - 0.04524886877828054% self-rule-following-consistency (using 221)\n",
      "                - 0.9728506787330317% self-comparison-consistency (using 221)\n",
      "                - 0.970873786407767% self-comparison-consistency==Y and ground-truth-consistent. (using 206)\n",
      "                - 0.0% self-comparison-consistency==N and not ground-truth-consistent. (using 15)\n",
      "                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                For run_1 run gpt-3.5-turbo including all answers\n",
      "                Evaluated 217 ambiguous sequences of 225 total.\n",
      "                Resulting in:\n",
      "                - 0.8294930875576036% ground-truth-consistent (using 217)\n",
      "                - 0.8433179723502304% self-rule-following-consistency (using 217)\n",
      "                - 0.9447004608294931% self-comparison-consistency (using 217)\n",
      "                - 0.9514563106796117% self-comparison-consistency==Y and ground-truth-consistent. (using 206)\n",
      "                - 0.09090909090909091% self-comparison-consistency==N and not ground-truth-consistent. (using 11)\n",
      "                \n",
      "\n",
      "                For run_2 run gpt-3.5-turbo including all answers\n",
      "                Evaluated 213 ambiguous sequences of 225 total.\n",
      "                Resulting in:\n",
      "                - 0.8309859154929577% ground-truth-consistent (using 213)\n",
      "                - 0.8497652582159625% self-rule-following-consistency (using 213)\n",
      "                - 0.9624413145539906% self-comparison-consistency (using 213)\n",
      "                - 0.9656862745098039% self-comparison-consistency==Y and ground-truth-consistent. (using 204)\n",
      "                - 0.0% self-comparison-consistency==N and not ground-truth-consistent. (using 9)\n",
      "                \n",
      "\n",
      "                For run_3 run gpt-3.5-turbo including all answers\n",
      "                Evaluated 212 ambiguous sequences of 225 total.\n",
      "                Resulting in:\n",
      "                - 0.8066037735849056% ground-truth-consistent (using 212)\n",
      "                - 0.8301886792452831% self-rule-following-consistency (using 212)\n",
      "                - 0.9575471698113207% self-comparison-consistency (using 212)\n",
      "                - 0.9554455445544554% self-comparison-consistency==Y and ground-truth-consistent. (using 202)\n",
      "                - 0.0% self-comparison-consistency==N and not ground-truth-consistent. (using 10)\n",
      "                \n",
      "\n",
      "                For run_1 run gpt-4-0314 including all answers\n",
      "                Evaluated 210 ambiguous sequences of 225 total.\n",
      "                Resulting in:\n",
      "                - 0.8761904761904762% ground-truth-consistent (using 210)\n",
      "                - 0.8761904761904762% self-rule-following-consistency (using 210)\n",
      "                - 0.8095238095238095% self-comparison-consistency (using 210)\n",
      "                - 0.8058252427184466% self-comparison-consistency==Y and ground-truth-consistent. (using 206)\n",
      "                - 0.0% self-comparison-consistency==N and not ground-truth-consistent. (using 4)\n",
      "                \n",
      "\n",
      "                For run_2 run gpt-4-0314 including all answers\n",
      "                Evaluated 211 ambiguous sequences of 225 total.\n",
      "                Resulting in:\n",
      "                - 0.8672985781990521% ground-truth-consistent (using 211)\n",
      "                - 0.8720379146919431% self-rule-following-consistency (using 211)\n",
      "                - 0.7867298578199052% self-comparison-consistency (using 211)\n",
      "                - 0.7874396135265701% self-comparison-consistency==Y and ground-truth-consistent. (using 207)\n",
      "                - 0.25% self-comparison-consistency==N and not ground-truth-consistent. (using 4)\n",
      "                \n",
      "\n",
      "                For run_3 run gpt-4-0314 including all answers\n",
      "                Evaluated 210 ambiguous sequences of 225 total.\n",
      "                Resulting in:\n",
      "                - 0.8666666666666667% ground-truth-consistent (using 210)\n",
      "                - 0.8666666666666667% self-rule-following-consistency (using 210)\n",
      "                - 0.8523809523809524% self-comparison-consistency (using 210)\n",
      "                - 0.8529411764705882% self-comparison-consistency==Y and ground-truth-consistent. (using 204)\n",
      "                - 0.16666666666666666% self-comparison-consistency==N and not ground-truth-consistent. (using 6)\n",
      "                \n",
      "\n",
      "                For run_1 run text-davinci-003 including all answers\n",
      "                Evaluated 222 ambiguous sequences of 225 total.\n",
      "                Resulting in:\n",
      "                - 0.6891891891891891% ground-truth-consistent (using 222)\n",
      "                - 0.7072072072072072% self-rule-following-consistency (using 222)\n",
      "                - 0.8783783783783784% self-comparison-consistency (using 222)\n",
      "                - 0.8916256157635468% self-comparison-consistency==Y and ground-truth-consistent. (using 203)\n",
      "                - 0.2631578947368421% self-comparison-consistency==N and not ground-truth-consistent. (using 19)\n",
      "                \n",
      "\n",
      "                For run_2 run text-davinci-003 including all answers\n",
      "                Evaluated 222 ambiguous sequences of 225 total.\n",
      "                Resulting in:\n",
      "                - 0.7027027027027027% ground-truth-consistent (using 222)\n",
      "                - 0.6981981981981982% self-rule-following-consistency (using 222)\n",
      "                - 0.8648648648648649% self-comparison-consistency (using 222)\n",
      "                - 0.8731707317073171% self-comparison-consistency==Y and ground-truth-consistent. (using 205)\n",
      "                - 0.23529411764705882% self-comparison-consistency==N and not ground-truth-consistent. (using 17)\n",
      "                \n",
      "\n",
      "                For run_3 run text-davinci-003 including all answers\n",
      "                Evaluated 225 ambiguous sequences of 225 total.\n",
      "                Resulting in:\n",
      "                - 0.6933333333333334% ground-truth-consistent (using 225)\n",
      "                - 0.6888888888888889% self-rule-following-consistency (using 225)\n",
      "                - 0.8755555555555555% self-comparison-consistency (using 225)\n",
      "                - 0.8792270531400966% self-comparison-consistency==Y and ground-truth-consistent. (using 207)\n",
      "                - 0.16666666666666666% self-comparison-consistency==N and not ground-truth-consistent. (using 18)\n",
      "                \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "models = [\n",
    "    \"davinci\", \"gpt-3.5-turbo\", \"gpt-4-0314\", \"text-davinci-003\"\n",
    "]\n",
    "runs = [\n",
    "    'run_1', 'run_2', 'run_3'\n",
    "]\n",
    "total_sequences = 225\n",
    "results = []\n",
    "for answer_validity in ['valid', 'all']:\n",
    "    for model in models:\n",
    "        for run in runs:\n",
    "            df = pd.read_csv(\n",
    "                    f'./{run}/compute_dependence_with_base_changes=False,sequence_completion_equality.model={model},string_transformation_completion_equality=False/evaluate_sequence_completion_equality/sequence_completion_equality_evaluation_{model}.csv'\n",
    "            )\n",
    "            \n",
    "            match_accs, model_match_accs, model_consistency_accs, consistent_and_matched_positive, consistent_and_matched_negative = (\n",
    "                [],\n",
    "                [],\n",
    "                [],\n",
    "                [],\n",
    "                []\n",
    "            )\n",
    "\n",
    "            for i, data in df.iterrows():\n",
    "                if answer_validity == 'valid' and  data[\"generated_completion_matches\"] is not True and data[\"generated_completion_matches\"] is not False:\n",
    "                    continue\n",
    "                match_accs.append(1 if data[\"generated_completion_matches\"] == True else 0)\n",
    "\n",
    "            for i, data in df.iterrows():\n",
    "                if answer_validity == 'valid' and data[\"model_completion_matches\"] is not True and data[\"model_completion_matches\"] is not False:\n",
    "                    continue\n",
    "                model_match_accs.append(1 if data[\"model_completion_matches\"] == True else 0)\n",
    "\n",
    "            for i, data in df.iterrows():\n",
    "                if answer_validity == 'valid' and data[\"model_self_consistency_evaluation\"].strip() != \"Y\" and data[\"model_self_consistency_evaluation\"].strip() != \"N\":\n",
    "                    continue\n",
    "                model_consistency_accs.append(\n",
    "                    1 if data[\"model_self_consistency_evaluation\"].strip() == \"Y\" else 0\n",
    "                )\n",
    "\n",
    "            for i, data in df.iterrows():\n",
    "                if answer_validity == 'valid' and data[\"model_self_consistency_evaluation\"].strip() != \"Y\" and data[\"model_self_consistency_evaluation\"].strip() != \"N\":\n",
    "                    continue\n",
    "                if answer_validity == 'valid' and  data[\"generated_completion_matches\"] is not True and data[\"generated_completion_matches\"] is not False:\n",
    "                    continue\n",
    "                if data[\"generated_completion_matches\"]:\n",
    "                    consistent_and_matched_positive.append(\n",
    "                        1\n",
    "                        if data[\"model_self_consistency_evaluation\"].strip() == \"Y\"\n",
    "                        else 0\n",
    "                    )\n",
    "                else:\n",
    "                    consistent_and_matched_negative.append(\n",
    "                        1\n",
    "                        if data[\"model_self_consistency_evaluation\"].strip() == \"N\"\n",
    "                        else 0\n",
    "                    )\n",
    "                    \n",
    "\n",
    "\n",
    "            ground_truth_consistent = np.mean(match_accs)\n",
    "            self_rule_following_consistency = np.mean(model_match_accs)\n",
    "            self_comparison_consistency = np.mean(model_consistency_accs)\n",
    "            consistent_and_matched_positive_acc = np.mean(consistent_and_matched_positive)\n",
    "            consistent_and_matched_negative_acc = np.mean(consistent_and_matched_negative)\n",
    "            print(\n",
    "                f\"\"\"\n",
    "                For {run} run {model} including {answer_validity} answers\n",
    "                Evaluated {len(df)} ambiguous sequences of {total_sequences} total.\n",
    "                Resulting in:\n",
    "                - {ground_truth_consistent}% ground-truth-consistent (using {len(match_accs)})\n",
    "                - {self_rule_following_consistency}% self-rule-following-consistency (using {len(model_match_accs)})\n",
    "                - {self_comparison_consistency}% self-comparison-consistency (using {len(model_consistency_accs)})\n",
    "                - {consistent_and_matched_positive_acc}% self-comparison-consistency==Y and ground-truth-consistent. (using {len(consistent_and_matched_positive)})\n",
    "                - {consistent_and_matched_negative_acc}% self-comparison-consistency==N and not ground-truth-consistent. (using {len(consistent_and_matched_negative)})\n",
    "                \"\"\"\n",
    "            )\n",
    "\n",
    "\n",
    "            results.append({\n",
    "                \"model\": model,\n",
    "                \"run\": run,\n",
    "                \"answer_validity\": answer_validity,\n",
    "                \"ground_truth_consistent\": round(ground_truth_consistent * 100, 2),\n",
    "                \"ground_truth_consistent_num\": len(match_accs),\n",
    "                \"self_rule_following_consistency\":  round(self_rule_following_consistency * 100, 2), \n",
    "                \"self_rule_following_consistency_len\": len(model_match_accs),\n",
    "                \"self_comparison_consistency\": round(self_comparison_consistency * 100, 2),\n",
    "                \"self_comparison_consistency_len\": len(model_consistency_accs),\n",
    "                \"consistent_and_matched_positive\": round(consistent_and_matched_positive_acc * 100, 2),\n",
    "                \"consistent_and_matched_positive_len\": len(consistent_and_matched_positive),\n",
    "                \"consistent_and_matched_negative\": round(consistent_and_matched_negative_acc * 100, 2),\n",
    "                \"consistent_and_matched_negative_len\": len(consistent_and_matched_negative)\n",
    "            })\n",
    "\n",
    "pd.DataFrame(results).to_csv('./q0_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "97c37b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "consistent_functions = []\n",
    "for model in models:\n",
    "    df = pd.read_csv(\n",
    "            f'./run_1/compute_dependence_with_base_changes=False,sequence_completion_equality.model={model},string_transformation_completion_equality=False/evaluate_sequence_completion_equality/sequence_completion_equality_evaluation_{model}.csv'\n",
    "    )\n",
    "    for i, data in df.iterrows():\n",
    "        if data[\"generated_completion_matches\"] is True:\n",
    "            consistent_functions.append({\n",
    "                \"fn\": data['original_function'],\n",
    "                \"model\": model\n",
    "            })\n",
    "            \n",
    "pd.DataFrame(\n",
    "    consistent_functions\n",
    ").to_csv('./consistent_functions_by_model.csv')\n",
    "            \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
