{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as pylab\n",
    "_DEFAULT_PARAMS = {'legend.fontsize': '16',\n",
    "          'figure.figsize': (8, 5),\n",
    "         'axes.labelsize': '16',\n",
    "         'axes.titlesize':'16',\n",
    "         'xtick.labelsize':'16',\n",
    "         'ytick.labelsize':'16'}\n",
    "pylab.rcParams.update(_DEFAULT_PARAMS)\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"paper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dir = \"results/q2_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(os.listdir(res_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_paths = []\n",
    "for par_dir, dirnames, _ in os.walk(res_dir):\n",
    "    for sub_dir in dirnames:\n",
    "        for dirpath, _, filenames in os.walk(os.path.join(par_dir, sub_dir)):\n",
    "            if \"results.csv\" in filenames:\n",
    "                csv_paths.append(os.path.join(dirpath, \"results.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_paths = list(set(csv_paths))\n",
    "csv_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pd.DataFrame()\n",
    "\n",
    "for csv_file in csv_paths:\n",
    "    df = pd.read_csv(csv_file, sep=\",\")\n",
    "    main_df = pd.concat([main_df, df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(csv_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(main_df))\n",
    "main_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(main_df[main_df[\"invalid_fn_type\"] == \"random\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df.groupby([\"num_shots\", \"invalid_fn_type\"])[\"test_passing_completion\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df.groupby([\"invalid_fn_type\"])[\"num_invalid\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_df = main_df.pivot_table(\n",
    "    index=[\"num_shots\", \"invalid_fn_type\"],\n",
    "    values=[\n",
    "        \"test_passing_completion\", \"test_passing_explanation\",\n",
    "        \"org_func\",\n",
    "        ],\n",
    "    aggfunc={\n",
    "        \"test_passing_completion\": \"sum\",\n",
    "        \"test_passing_explanation\": \"sum\",\n",
    "        \"org_func\": \"count\",\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pivot_df.copy()\n",
    "final_df[\"test_passing_completion\"] = final_df[\"test_passing_completion\"] / final_df[\"org_func\"]\n",
    "final_df[\"test_passing_explanation\"] = final_df[\"test_passing_explanation\"] / final_df[\"org_func\"]\n",
    "final_df[\"n_examples\"] = final_df[\"org_func\"]\n",
    "final_df = final_df.drop(columns=[\"org_func\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_df[\"test_passing_completion\"].mean())\n",
    "print(final_df[\"test_passing_explanation\"].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(os.path.join(res_dir, \"1018_q2_1_agg_ns4,6,8,10.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ungrouped_df = final_df.reset_index()\n",
    "ungrouped_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure and a set of subplots\n",
    "\n",
    "pylab.rcParams.update(_DEFAULT_PARAMS)\n",
    "\n",
    "fig, axis = plt.subplots(1, ncols=2, figsize=(12, 6), sharey=\"row\")\n",
    "\n",
    "cols = [\"test_passing_completion\", \"test_passing_explanation\"]\n",
    "\n",
    "# The amount of space for each group of bars along the x-axis\n",
    "width = 0.2\n",
    "\n",
    "# The x locations for the groups\n",
    "x = np.arange(len(ungrouped_df['num_shots'].unique()))\n",
    "\n",
    "for idx, col in enumerate(cols):\n",
    "    ax = axis[idx]\n",
    "\n",
    "    # Divide the data into classes\n",
    "    compl_a = ungrouped_df[ungrouped_df['invalid_fn_type'] == 'exclude_class'][col]\n",
    "    compl_b = ungrouped_df[ungrouped_df['invalid_fn_type'] == 'same_class'][col]\n",
    "    compl_c = ungrouped_df[ungrouped_df['invalid_fn_type'] == 'random'][col]\n",
    "\n",
    "    # Create the lines\n",
    "    rects1 = ax.plot(x, compl_a, label='exclude_class', marker='o')\n",
    "    rects2 = ax.plot(x, compl_b, label='same_class', marker='o')\n",
    "    rects3 = ax.plot(x, compl_c, label='random_class', marker='o')\n",
    "\n",
    "    ax.set_xlabel('Number of Shots')\n",
    "\n",
    "    if idx == 0:\n",
    "        ax.set_ylabel('Test Passing Rate')\n",
    "        ax.legend(loc='lower right')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(ungrouped_df['num_shots'].unique())\n",
    "    ax.title.set_text(col)\n",
    "    ax.set_ylim(bottom=0.2, top=1)\n",
    "\n",
    "st = fig.suptitle(\"Test Passing by Number of Shots and Invalid Function Type\", fontsize=\"x-large\")\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"1018_logprob_rate.pdf\", format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_df = main_df.pivot_table(\n",
    "    index=[\"num_shots\", \"invalid_fn_type\"],\n",
    "    values=[\n",
    "        \"test_passing_completion\",\n",
    "        \"org_func\",\n",
    "        ],\n",
    "    aggfunc={\n",
    "        \"test_passing_completion\": \"sum\",\n",
    "        \"org_func\": \"count\",\n",
    "    })\n",
    "\n",
    "pivot_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pivot_df.copy()\n",
    "final_df[\"test_passing_completion\"] = round(final_df[\"test_passing_completion\"] / final_df[\"org_func\"], 3)\n",
    "final_df[\"n_examples\"] = final_df[\"org_func\"]\n",
    "final_df = final_df.drop(columns=[\"org_func\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = final_df.reset_index()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## LINE Plot\n",
    "# completion for across number of shots\n",
    "df = main_df\n",
    "\n",
    "fig = plt.figure(figsize=_DEFAULT_PARAMS.get('figure.figsize'))\n",
    "\n",
    "# Define the order of hues (class labels) you want\n",
    "hue_order = [\"random\", \"exclude_class\", \"same_class\"]\n",
    "\n",
    "# Define a custom color palette for specific labels\n",
    "custom_palette = {\n",
    "    'random': \"blue\",\n",
    "    'exclude_class': \"green\",\n",
    "    'same_class': \"orange\",\n",
    "\n",
    "}\n",
    "\n",
    "# Calculate normalized histograms for each class using Seaborn\n",
    "g = sns.lineplot(data=df, x='num_shots',\n",
    "             y=\"test_passing_completion\",\n",
    "             hue='invalid_fn_type',\n",
    "             hue_order=hue_order,\n",
    "             palette=custom_palette,\n",
    "             marker=\"o\",\n",
    "             errorbar=(\"sd\", 0.0),\n",
    "             #legend=False,\n",
    "             )\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Number of Shots')\n",
    "plt.xticks([4, 6, 8, 10])\n",
    "plt.ylabel('Rate')\n",
    "plt.ylim(bottom=0.72, top=0.90)\n",
    "plt.title('Rate for Correct Completions Assigned Consistently Non-trivial Mass')\n",
    "leg = plt.legend(fontsize=16, title=\"invalid func type\")\n",
    "plt.setp(leg.get_title(), fontsize='x-large')\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"1018_logprob_rate_completions.pdf\", format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logprob Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_paths = []\n",
    "for par_dir, dirnames, _ in os.walk(res_dir):\n",
    "    for sub_dir in dirnames:\n",
    "        for dirpath, _, filenames in os.walk(os.path.join(par_dir, sub_dir)):\n",
    "            if \"logprobs.csv\" in filenames:\n",
    "                csv_paths.append(os.path.join(dirpath, \"logprobs.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_paths = list(set(csv_paths))\n",
    "csv_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pd.DataFrame()\n",
    "\n",
    "for csv_file in csv_paths:\n",
    "    try:\n",
    "        df = pd.read_csv(csv_file, sep=\",\")\n",
    "    except:\n",
    "        print(\"Error reading file: {}\".format(csv_file))\n",
    "    main_df = pd.concat([main_df, df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(csv_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(main_df))\n",
    "main_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df.to_csv(os.path.join(res_dir, \"1018_q2_1_logprobs_agg_ns4,6,8,10.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df[[\"valid_and_pred\", \"invalid_and_pred\",\"valid_and_not_pred\", \"invalid_and_not_pred\"]].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df[\"correct\"] = main_df[\"valid\"]\n",
    "main_df.loc[main_df[\"valid\"] == \"valid\", \"correct\"] = \"correct\"\n",
    "main_df.loc[main_df[\"valid\"] == \"invalid\", \"correct\"] = \"incorrect\"\n",
    "\n",
    "main_df[\"correct_and_pred\"] = main_df[\"valid_and_pred\"]\n",
    "main_df[\"incorrect_and_pred\"] = main_df[\"invalid_and_pred\"]\n",
    "main_df[\"correct_and_not_pred\"] = main_df[\"valid_and_not_pred\"]\n",
    "main_df[\"incorrect_and_not_pred\"] = main_df[\"invalid_and_not_pred\"]\n",
    "main_df = main_df.drop([\"valid\", \"valid_and_pred\", \"invalid_and_pred\", \"valid_and_not_pred\", \"invalid_and_not_pred\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use numpy select to create the \"class_label\" column based on conditions\n",
    "conditions = [\n",
    "    main_df['correct_and_pred'] == 1,\n",
    "    main_df['incorrect_and_not_pred'] == 1,\n",
    "    main_df['correct_and_not_pred'] == 1,\n",
    "    main_df['incorrect_and_pred'] == 1\n",
    "]\n",
    "\n",
    "choices = ['correct_and_pred', 'incorrect_and_not_pred', 'correct_and_not_pred', 'incorrect_and_pred']\n",
    "\n",
    "main_df.loc[:, 'class_label'] = np.select(conditions, choices, default=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df.groupby([\"num_shots\"])[['correct_and_pred', 'correct_and_not_pred', 'incorrect_and_pred', 'incorrect_and_not_pred',]].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df.to_csv(os.path.join(res_dir, \"1018_q2_1_logprobs_w_class_labels.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df.groupby([\"num_shots\", \"invalid_fn_type\", \"response_type\", \"correct\"])[\"logprob\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df[\"num_valid\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_type = \"random\"\n",
    "conditions = (main_df[\"response_type\"] == \"completion\") & (main_df[\"num_shots\"] > 2) & (main_df[\"invalid_fn_type\"] == fn_type) & (main_df[\"correct\"] != \"pred\")\n",
    "main_df[conditions].groupby([\"num_shots\"])[\"class_label\"].value_counts()\n",
    "round(main_df[conditions].groupby([\"num_shots\"])[\"class_label\"].value_counts() / main_df[conditions].groupby([\"num_shots\"])[\"class_label\"].count() * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(main_df[conditions].groupby([\"num_shots\"])[\"correct\"].value_counts() / main_df[conditions].groupby([\"num_shots\"])[\"correct\"].count() * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pivot_df = main_df.pivot_table(\n",
    "    index=[\"num_shots\", \"invalid_fn_type\", \"response_type\", \"correct\"],\n",
    "    values=[\n",
    "        \"logprob\",\n",
    "        ],\n",
    "    aggfunc={\n",
    "        \"logprob\": [np.mean, \"std\", \"count\", \"min\", \"max\"],\n",
    "\n",
    "    })\n",
    "\n",
    "pivot_df.columns = [f'{aggfunc}_{column}' for column, aggfunc in pivot_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DENSITY Plot\n",
    "# completion for specific number of shots across function types\n",
    "params = {'legend.fontsize': '16',\n",
    "          'figure.figsize': (8, 5),\n",
    "         'axes.labelsize': '16',\n",
    "         'axes.titlesize':'16',\n",
    "         'xtick.labelsize':'16',\n",
    "         'ytick.labelsize':'16'}\n",
    "pylab.rcParams.update(params)\n",
    "\n",
    "num_shots = 8\n",
    "model = \"text-davinci-003\"\n",
    "response_type = \"completion\"\n",
    "\n",
    "conditions = (main_df['response_type'] == response_type) & (main_df[\"correct\"] != \"pred\") & (main_df['num_shots'] == num_shots) & (main_df[\"model\"] == model)\n",
    "df = main_df[conditions]\n",
    "\n",
    "fig = plt.figure(figsize=params.get('figure.figsize'))\n",
    "\n",
    "# Define the order of hues (class labels) you want\n",
    "#hue_order = df['class_label'].unique().tolist()\n",
    "hue_order = ['correct_and_not_pred', 'incorrect_and_not_pred', 'correct_and_pred', 'incorrect_and_pred',]\n",
    "\n",
    "# Define a custom color palette for specific labels\n",
    "custom_palette = {\n",
    "    'correct_and_not_pred': 'green',\n",
    "    'correct_and_pred': 'blue',\n",
    "    'incorrect_and_not_pred': 'orange',\n",
    "    'incorrect_and_pred': 'red',\n",
    "\n",
    "}\n",
    "\n",
    "# Calculate normalized histograms for each class using Seaborn\n",
    "sns.histplot(data=df, x='logprob', hue='class_label', palette=custom_palette, bins=15, common_norm=False, kde=True, stat='density',\n",
    "            alpha=0.2, linewidth=.15)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Log Probability')\n",
    "plt.ylim(top=0.55)\n",
    "plt.xlim(left=-35)\n",
    "plt.ylabel('Normalized Density')\n",
    "leg = plt.legend(labels=hue_order, fontsize=16, title=\"class label\", loc=\"upper left\")\n",
    "plt.setp(leg.get_title(), fontsize='x-large')\n",
    "plt.title('Distribution of Log Probabilities by Class Label for Completion (num_shots = {})'.format(num_shots))\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"1018_logprob_distribution.pdf\", format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"class_label\"])[\"logprob\"].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DENSITY Plot\n",
    "# completion for specific number of shots across function types\n",
    "num_shots = 8\n",
    "model = \"text-davinci-003\"\n",
    "response_type = \"completion\"\n",
    "fn_type = \"random\"\n",
    "\n",
    "conditions = (main_df['num_shots'] == num_shots) & (main_df['invalid_fn_type'] == fn_type) & (main_df['response_type'] == response_type) & (main_df[\"correct\"] != \"pred\") & (main_df[\"model\"] == model)\n",
    "df = main_df[conditions]\n",
    "\n",
    "fig = plt.figure(figsize=_DEFAULT_PARAMS.get('figure.figsize'))\n",
    "\n",
    "# Define the order of hues (class labels) you want\n",
    "#hue_order = df['class_label'].unique().tolist()\n",
    "hue_order = ['correct', 'incorrect']\n",
    "\n",
    "# Define a custom color palette for specific labels\n",
    "custom_palette = {\n",
    "    'correct': 'blue',\n",
    "    'incorrect': 'orange',\n",
    "}\n",
    "\n",
    "# Calculate normalized histograms for each class using Seaborn\n",
    "sns.histplot(data=df, x='logprob', hue='correct', palette=custom_palette, bins=50, common_norm=True, kde=True, stat='density',\n",
    "            alpha=0.2, linewidth=.15)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Log Probability')\n",
    "plt.ylabel('Normalized Density')\n",
    "plt.title('Normalized Distribution of Log Probabilities by Correctness for Completion (num_shots = {})'.format(num_shots))\n",
    "plt.tight_layout()\n",
    "plt.ylim(top=0.185)\n",
    "plt.legend(labels=['incorrect', 'correct',])\n",
    "fig.savefig(\"1018_normalized_logprob_distribution.pdf\", format='pdf', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"correct_and_pred\", \"incorrect_and_not_pred\", \"correct_and_not_pred\", \"incorrect_and_pred\",]\n",
    "\n",
    "# Create a figure and a set of subplots per num_shot value\n",
    "fig, axis = plt.subplots(2, 2, figsize=(20, 12), sharex=\"col\")\n",
    "ax_loc = [(0, 0), (0, 1), (1, 0), (1, 1)]\n",
    "\n",
    "response_type = \"completion\"\n",
    "shots = sorted(main_df[\"num_shots\"].unique())\n",
    "\n",
    "model = \"text-davinci-003\"\n",
    "df = main_df[(main_df['response_type'] == response_type) & (main_df[\"correct\"] != \"pred\") & (main_df[\"model\"] == model)]\n",
    "\n",
    "for n_shot, loc in zip(shots, ax_loc):\n",
    "    ax = axis[loc]\n",
    "\n",
    "    # For each type of validity, create a histogram\n",
    "    for col in cols:\n",
    "\n",
    "        # select data for n_shot\n",
    "        valid_df = df[(df[\"num_shots\"] == n_shot) & (df[col] == 1)]\n",
    "\n",
    "        # If there is data for this combination\n",
    "        sns.histplot(valid_df['logprob'], kde=True, label=col, stat=\"density\", common_norm=False,\n",
    "                alpha=0.2, linewidth=.15, ax=ax)\n",
    "\n",
    "    if loc[0] == 1:\n",
    "        ax.set_xlabel('Log Probability')\n",
    "\n",
    "    ax.title.set_text(f\"num_shots = {n_shot}\")\n",
    "    ax.legend(loc='upper left')\n",
    "\n",
    "st = fig.suptitle(f\"Log Probability Distribution by Validity for '{response_type}' across num_shots\", fontsize=\"x-large\")\n",
    "st.set_y(0.95)\n",
    "fig.subplots_adjust(top=0.85)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DENSITY Plot\n",
    "# completion for all functions across number of shots\n",
    "num_shots = 10\n",
    "model = \"text-davinci-003\"\n",
    "response_type = \"completion\"\n",
    "invalid_fn = \"random\"\n",
    "# & (main_df['invalid_fn_type'] == invalid_fn)\n",
    "df = main_df[(main_df['response_type'] == response_type) & (main_df[\"correct\"] != \"pred\") & (main_df['num_shots'] == num_shots)  & (main_df[\"model\"] == model) & (main_df['invalid_fn_type'] == invalid_fn)]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "# Define the order of hues (class labels) you want\n",
    "#hue_order = df['class_label'].unique().tolist()\n",
    "hue_order = ['correct_and_pred', 'correct_and_not_pred', 'incorrect_and_pred', 'incorrect_and_not_pred', ]\n",
    "\n",
    "# Define a custom color palette for specific labels\n",
    "custom_palette = {\n",
    "    'correct_and_not_pred': 'green',\n",
    "    'correct_and_pred': 'blue',\n",
    "    'incorrect_and_not_pred': 'orange',\n",
    "    'incorrect_and_pred': 'red',\n",
    "\n",
    "}\n",
    "\n",
    "# Calculate normalized histograms for each class using Seaborn\n",
    "sns.histplot(data=df, x='logprob', hue='class_label', palette=custom_palette, bins=60, common_norm=False, kde=True, stat='density',\n",
    "            alpha=0.2, linewidth=.15)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Log Probability')\n",
    "plt.ylabel('Density')\n",
    "plt.ylim(top=0.5)\n",
    "#plt.legend(title=\"class label\")\n",
    "plt.title('Distribution of Log Probabilities by Class Label for Completion (num_shots = {})'.format(num_shots))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Calculate normalized histograms for each class using Seaborn\n",
    "sns.histplot(data=df, x='logprob', hue='class_label', palette=custom_palette, bins=60, common_norm=True, kde=True, stat='density',\n",
    "            alpha=0.2, linewidth=.15)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Log Probability')\n",
    "plt.ylabel('Noramlized Density')\n",
    "plt.title('Normalized Distribution of Log Probabilities by Class Label for Completion (num_shots = {})'.format(num_shots))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DENSITY Plot\n",
    "# completion for all functions across all number of shots\n",
    "# num_shots = 10\n",
    "model = \"text-davinci-003\"\n",
    "response_type = \"completion\"\n",
    "# invalid_fn = \"random\"\n",
    "# & (main_df['invalid_fn_type'] == invalid_fn)\n",
    "df = main_df[(main_df['response_type'] == response_type) & (main_df[\"correct\"] != \"pred\") & (main_df[\"model\"] == model)]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "# Define the order of hues (class labels) you want\n",
    "hue_order = ['correct_and_pred', 'correct_and_not_pred', 'incorrect_and_pred', 'incorrect_and_not_pred', ]\n",
    "\n",
    "# Define a custom color palette for specific labels\n",
    "custom_palette = {\n",
    "    'correct_and_not_pred': 'green',\n",
    "    'correct_and_pred': 'blue',\n",
    "    'incorrect_and_not_pred': 'orange',\n",
    "    'incorrect_and_pred': 'red',\n",
    "\n",
    "}\n",
    "\n",
    "# Calculate normalized histograms for each class using Seaborn\n",
    "sns.histplot(data=df, x='logprob', hue='class_label', palette=custom_palette, bins=80, common_norm=False, kde=True, stat='density',\n",
    "            alpha=0.2, linewidth=.15)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Log Probability')\n",
    "plt.ylabel('Density')\n",
    "plt.ylim(top=0.65)\n",
    "plt.title('Distribution of Log Probabilities by Class Label for Completion (num_shots = {})'.format(\"all\"))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## COUNT Plot\n",
    "\n",
    "cols = [\"correct_and_pred\", \"incorrect_and_not_pred\", \"correct_and_not_pred\", \"incorrect_and_pred\",]\n",
    "\n",
    "# filter the dataframe according to your conditions\n",
    "num_shots = 10\n",
    "model = \"text-davinci-003\"\n",
    "response_type = \"completion\"\n",
    "\n",
    "df = main_df[(main_df['response_type'] == response_type) & (main_df['num_shots'] == num_shots) & (main_df[\"model\"] == model)]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# For each type of validity, create a histogram\n",
    "for col in cols:\n",
    "    valid_df = df[df[col] == 1]\n",
    "\n",
    "    # If there is data for this combination\n",
    "    sns.histplot(valid_df['logprob'], kde=True, label=col, stat=\"count\", common_norm=False,\n",
    "            alpha=0.2, linewidth=.15)\n",
    "\n",
    "plt.xlabel('Log Probability')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Log Probability Distribution by Validity for \"{}\" (num_shots = {})'.format(response_type, num_shots))\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KL Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import rel_entr\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "def calculate_kl_for_num_shots(main_df, p_label=\"correct_and_pred\", q_label=\"correct_and_not_pred\", num_shots = None, nbins=40, sigma_smoothing=1):\n",
    "\n",
    "    conditions =  (main_df[\"invalid_fn_type\"] == \"random\") & (main_df[\"response_type\"] == \"completion\") & (main_df[\"model\"] == \"text-davinci-003\")\n",
    "    if num_shots is not None:\n",
    "        conditions = conditions & (main_df[\"num_shots\"] == num_shots)\n",
    "\n",
    "    p_label = main_df[conditions & (main_df[\"class_label\"] == p_label)][\"logprob\"] # P\n",
    "    q_label = main_df[conditions & (main_df[\"class_label\"] == q_label)][\"logprob\"] # Q\n",
    "\n",
    "    # get bins according to min and max of P and Q distributions\n",
    "    bins = np.linspace(max(p_label.max(), q_label.max()), min(p_label.min(), q_label.min()), num=nbins)[::-1]  # min to max\n",
    "\n",
    "    p_density = np.histogram(p_label, bins=bins, density=True)[0]\n",
    "    q_density = np.histogram(q_label, bins=bins, density=True)[0]\n",
    "\n",
    "    if sigma_smoothing is not None:\n",
    "        # apply gaussian filter smoothing to remove 0 entries\n",
    "        p_smoothed = gaussian_filter(p_density, sigma_smoothing)\n",
    "        q_smoothed = gaussian_filter(q_density, sigma_smoothing)\n",
    "        return round(sum(rel_entr(p_smoothed, q_smoothed, where=q_density > 0)), 3)\n",
    "    else:\n",
    "        return round(sum(rel_entr(p_density, q_density, where=q_density > 0)), 3)\n",
    "\n",
    "\n",
    "def print_kl_divergences(p_label, q_label):\n",
    "\n",
    "    print(\"KL(P||Q) in bits between P := {} and Q := {}\".format(p_label, q_label))\n",
    "    print(\"Across num_shots & w/o smoothing: \", calculate_kl_for_num_shots(main_df, p_label=p_label, q_label=q_label, sigma_smoothing=None))\n",
    "    print(\"Across num_shots & w/ smoothing: \", calculate_kl_for_num_shots(main_df, p_label=p_label, q_label=q_label,))\n",
    "    print(\"Across num_shots & w/ 2-sigma smoothing: \", calculate_kl_for_num_shots(main_df, p_label=p_label, q_label=q_label, sigma_smoothing=2))\n",
    "    print(\"\\nnum_shots=8 & w/o smoothing: \", calculate_kl_for_num_shots(main_df, p_label=p_label, q_label=q_label,num_shots=8, sigma_smoothing=None))\n",
    "    print(\"num_shots=8 & w/ smoothing: \", calculate_kl_for_num_shots(main_df, p_label=p_label, q_label=q_label,num_shots=8))\n",
    "    print(\"num_shots=8 & w/ 2-sigma smoothing: \", calculate_kl_for_num_shots(main_df, p_label=p_label, q_label=q_label, num_shots=8, sigma_smoothing=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_label = \"correct_and_pred\"\n",
    "q_label = \"correct_and_pred\"\n",
    "\n",
    "print_kl_divergences(p_label, q_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_label = \"correct_and_pred\"\n",
    "q_label = \"correct_and_not_pred\"\n",
    "\n",
    "print_kl_divergences(p_label, q_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_label = \"correct_and_pred\"\n",
    "q_label = \"incorrect_and_not_pred\"\n",
    "\n",
    "print_kl_divergences(p_label, q_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_label = \"correct_and_pred\"\n",
    "q_label = \"incorrect_and_pred\"\n",
    "\n",
    "print_kl_divergences(p_label, q_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_label = \"correct_and_not_pred\"\n",
    "q_label = \"correct_and_pred\"\n",
    "print_kl_divergences(p_label, q_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_label = \"correct_and_not_pred\"\n",
    "q_label = \"incorrect_and_not_pred\"\n",
    "print_kl_divergences(p_label, q_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310_aisc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
