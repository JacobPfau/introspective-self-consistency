[2023-05-18 20:05:00,612][src.utils][INFO] - Git sha: c88a972630012a00b49c97de24b75da3baa2f543
[2023-05-18 20:05:00,620][src.utils][INFO] - Changed files: ['conf/tasks/compute_dependence_with_base_changes.yaml', 'src/evals/check_self_consistency.py', 'src/evals/prompts/distribution_prompt.py', 'src/evals/prompts/explanation_prompt.py']
[2023-05-18 20:05:00,629][src.utils][INFO] - Git diff:
diff --git a/conf/tasks/compute_dependence_with_base_changes.yaml b/conf/tasks/compute_dependence_with_base_changes.yaml
index d2b79eb..25bfb79 100644
--- a/conf/tasks/compute_dependence_with_base_changes.yaml
+++ b/conf/tasks/compute_dependence_with_base_changes.yaml
@@ -1,4 +1,4 @@
-sequence_type: integer
+sequence_type: binary
 model: gpt-3.5-turbo
 num_shots: 4
 on_ambiguous_sequences: true
diff --git a/src/evals/check_self_consistency.py b/src/evals/check_self_consistency.py
index 850af02..9cf6817 100644
--- a/src/evals/check_self_consistency.py
+++ b/src/evals/check_self_consistency.py
@@ -114,6 +114,10 @@ def self_consistency_evaluation(

         # Check consistency
         print("implied_continuation: ", implied_continuation)
+        # get the continuation in decimal
+        if base == 2:
+            pass
+
         print("continuation: ", continuation)
         if int_response == int(implied_continuation):
             consistent_explanations += 1
diff --git a/src/evals/prompts/distribution_prompt.py b/src/evals/prompts/distribution_prompt.py
index 2875bab..327e1bf 100644
--- a/src/evals/prompts/distribution_prompt.py
+++ b/src/evals/prompts/distribution_prompt.py
@@ -8,6 +8,7 @@ SELF_CONTINUATION_PROMPT = (

 SELF_EXPLANATION_PROMPT = """In your opinion, what is the most likely function which generated the following sequence?
 Assume the first number was generated by f(0), the second by f(1), and so on.
+The function should output a binary string prefixed by 0b, i.e. '0b1010'.
 Give your response in the format:
 Explanation: <function>
 """
diff --git a/src/evals/prompts/explanation_prompt.py b/src/evals/prompts/explanation_prompt.py
index 0d13a0c..665adc9 100644
--- a/src/evals/prompts/explanation_prompt.py
+++ b/src/evals/prompts/explanation_prompt.py
@@ -119,6 +119,7 @@ def generate_exp_shot_prompt(
         text += "Explanation: "
         text += fn
         text += "\n"
+        text += "\n"
         return text

     elif model_name == "gpt-3.5-turbo":
