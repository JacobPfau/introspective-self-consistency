{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as pylab\n",
    "_DEFAULT_PARAMS = {'legend.fontsize': '16',\n",
    "          'figure.figsize': (8, 5),\n",
    "         'axes.labelsize': '16',\n",
    "         'axes.titlesize':'16',\n",
    "         'xtick.labelsize':'16',\n",
    "         'ytick.labelsize':'16'}\n",
    "pylab.rcParams.update(_DEFAULT_PARAMS)\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"paper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dir = \"results/q2_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(os.listdir(res_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_paths = []\n",
    "for par_dir, dirnames, _ in os.walk(res_dir):\n",
    "    for sub_dir in dirnames:\n",
    "        for dirpath, _, filenames in os.walk(os.path.join(par_dir, sub_dir)):\n",
    "            if \"results.csv\" in filenames:\n",
    "                csv_paths.append(os.path.join(dirpath, \"results.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_paths = list(set(csv_paths))\n",
    "csv_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pd.DataFrame()\n",
    "\n",
    "for csv_file in csv_paths:\n",
    "    df = pd.read_csv(csv_file, sep=\",\")\n",
    "    main_df = pd.concat([main_df, df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(csv_paths)  # 230823: 3 runs x 4 num_shots x 3 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(main_df))\n",
    "main_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df.groupby([\"model\", \"num_shots\", \"n_possible_completions\"])[\"recall_compl\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df.groupby([\"model\", \"num_shots\", ])[\"precision_compl\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = main_df[main_df[\"model\"] != \"davinci\"]\n",
    "\n",
    "pivot_df = df.pivot_table(\n",
    "    index=[\"num_shots\", \"model\"],\n",
    "    values=[\n",
    "        \"precision_compl\", \"recall_compl\",\n",
    "        \"precision_expl\", \"recall_expl\",\n",
    "        ],\n",
    "    aggfunc={\n",
    "        \"precision_compl\": [\"mean\", \"std\"],\n",
    "        \"recall_compl\": [\"mean\", \"std\"],\n",
    "        \"precision_expl\": [\"mean\", \"std\"],\n",
    "        \"recall_expl\": [\"mean\", \"std\"],\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ungrouped_df = pivot_df.reset_index()\n",
    "ungrouped_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_df.to_csv(os.path.join(res_dir, \"1018_agg3runs.csv\"), index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ungrouped_df = pivot_df.reset_index()\n",
    "ungrouped_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ungrouped_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ungrouped_df.reset_index()\n",
    "ungrouped_df.columns = [\"num_shots\", \"model\", \"precision_completion_mean\", \"precision_completion_std\", \"recall_completion_mean\", \"recall_completion_std\",\n",
    "                        \"precision_explanation_mean\", \"precision_explanation_std\", \"recall_explanation_mean\", \"recall_explanation_std\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ungrouped_df[\"model\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace full model names with simple names\n",
    "ungrouped_df[\"model\"] = ungrouped_df[\"model\"].replace({\"gpt-3.5-turbo-0301\": \"gpt-3.5-turbo\", \"gpt-4-0314\": \"gpt-4\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the DataFrame using melt\n",
    "\n",
    "# Define the value_vars for each set of columns\n",
    "value_vars = [\"precision_completion_mean\", \"precision_completion_std\", \"recall_completion_mean\", \"recall_completion_std\",\n",
    "                        \"precision_explanation_mean\", \"precision_explanation_std\", \"recall_explanation_mean\", \"recall_explanation_std\"]\n",
    "\n",
    "melted_df = pd.melt(ungrouped_df, id_vars=['num_shots', 'model'], value_vars=value_vars, var_name='response_type_tmp', value_name='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_df[\"response_type_tmp\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the response type and metric type from the variable name\n",
    "melted_df['response_type'] = melted_df['response_type_tmp'].str.split('_').str[1]\n",
    "melted_df['metric_type'] = melted_df['response_type_tmp'].str.split('_').str[0]\n",
    "melted_df['stat'] = melted_df['response_type_tmp'].str.split('_').str[2]\n",
    "\n",
    "# Drop the unnecessary columns\n",
    "melted_df.drop(columns=['response_type_tmp'], inplace=True)\n",
    "\n",
    "# Reorder columns\n",
    "new_columns_order = ['num_shots', 'model', 'response_type', 'metric_type', \"stat\", \"value\"]\n",
    "melted_df = melted_df[new_columns_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean = melted_df[melted_df[\"stat\"] == \"mean\"].drop(\"stat\", axis=1)\n",
    "df_std = melted_df[melted_df[\"stat\"] == \"std\"].drop(\"stat\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_mean[df_mean[\"metric_type\"] == \"recall\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"value\"] < 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"num_shots\", \"model\", \"response_type\"])[\"value\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LINEPLOT\n",
    "metric = \"precision\"\n",
    "df = df_mean[df_mean[\"metric_type\"] == metric]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "# Define the order of hues (class labels) you want\n",
    "hue_order = ['text-davinci-003', 'gpt-3.5-turbo', 'gpt-4']\n",
    "\n",
    "# Define a custom color palette for specific labels\n",
    "custom_palette = {\n",
    "    'text-davinci-003': \"blue\",\n",
    "    'gpt-3.5-turbo': \"green\",\n",
    "    'gpt-4': \"orange\",\n",
    "\n",
    "}\n",
    "\n",
    "sns.lineplot(data=df, x='num_shots',\n",
    "             y=\"value\",  # [df[\"metric_type\"] == metric]\n",
    "             hue='model',\n",
    "             style=\"response_type\",\n",
    "             palette=custom_palette,\n",
    "             marker=\"o\",\n",
    "             )\n",
    "\n",
    "# sns.lineplot(data=df, x='num_shots',\n",
    "#             y=\"value\",\n",
    "#              hue='model',\n",
    "#              style=\"response_type\",\n",
    "#              palette=custom_palette,\n",
    "#              marker=\"x\",\n",
    "#              dashes=True, )\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Number of Shots')\n",
    "plt.xticks(df[\"num_shots\"].unique())\n",
    "plt.ylabel('Score')\n",
    "plt.title('Precision over Verbalized Answers')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean = melted_df[melted_df[\"stat\"] == \"mean\"].drop(\"stat\", axis=1)\n",
    "df_std = melted_df[melted_df[\"stat\"] == \"std\"].drop(\"stat\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_mean[df_mean[\"metric_type\"] == \"recall\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as pylab\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"paper\")\n",
    "\n",
    "# create subplots\n",
    "# plot prec & recall on different axis\n",
    "# ship it!\n",
    "fontsize=16\n",
    "params = {\n",
    "    'legend.fontsize': fontsize,\n",
    "    \"legend.title_fontsize\": \"16\",\n",
    "          'figure.figsize': (8, 10),\n",
    "         'axes.labelsize': '16',\n",
    "         'axes.titlesize':'16',\n",
    "         'xtick.labelsize':'16',\n",
    "         'ytick.labelsize':'16'}\n",
    "pylab.rcParams.update(params)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=1)\n",
    "\n",
    "\n",
    "\n",
    "df = df_mean\n",
    "hue_order = ['text-davinci-003', 'gpt-3.5-turbo', \"gpt-4\"]\n",
    "\n",
    "# Define a custom color palette for specific labels\n",
    "custom_palette = {\n",
    "    'text-davinci-003': \"tab:green\",\n",
    "    'gpt-3.5-turbo': \"tab:blue\",\n",
    "    \"gpt-4\": \"tab:orange\",\n",
    "\n",
    "}\n",
    "\n",
    "for metric, ax in zip([\"precision\", \"recall\"], axes):\n",
    "\n",
    "    # Calculate normalized histograms for each class using Seaborn\n",
    "    if metric == \"recall\":\n",
    "        legend=True\n",
    "    else:\n",
    "        legend=False\n",
    "\n",
    "    sns.lineplot(data=df, x='num_shots',\n",
    "                y=df[df[\"metric_type\"] == metric][\"value\"],\n",
    "                hue='model',\n",
    "                style=\"response_type\",\n",
    "                palette=custom_palette,\n",
    "                marker=\"o\",\n",
    "                ax=ax,\n",
    "                legend=legend,\n",
    "                )\n",
    "    ax.title.set_text(metric) # , fontdict={'fontsize': '16'}\n",
    "    #ax.title.fontsize = fontsize\n",
    "    #ax.xtick.labelsize = fontsize\n",
    "    ax.set_xticks(df[\"num_shots\"].unique())\n",
    "    ax.set_xlabel(\"Number of Shots\", fontdict={\"fontsize\": 16})\n",
    "    ax.set_ylabel(\"Score\", fontdict={\"fontsize\": 16})\n",
    "\n",
    "    if legend:\n",
    "        #leg = ax.legend(fontsize=16, ncol=2, bbox_to_anchor=(1.3, -.1))\n",
    "        pass\n",
    "\n",
    "st = fig.suptitle(\"Precision & Recall of Verbalized Alternatives by Model\", fontsize=16)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"1018_verbalize_precision.pdf\", format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = (main_df[\"model\"] != \"davinci\")\n",
    "main_df[conditions][\"sequence\"].value_counts().sum() / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df[conditions][\"n_possible_completions\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df[conditions][\"n_possible_explanations\"].value_counts() # divide by n_runs = 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310_aisc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
